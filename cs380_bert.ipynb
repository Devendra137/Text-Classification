{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgmSvpcqiI0i",
        "outputId": "e54fde04-bdfb-47bd-99df-d0b5ab9a46bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nqrv1CH3jBa8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/hate_speech_dataset.csv\", index_col=0)"
      ],
      "metadata": {
        "id": "mF7GqVpOjTE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVkrbByNjZXk",
        "outputId": "f7ddb382-3a43-4c50-d9ea-57e34bc72d3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 24783 entries, 0 to 25296\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   class   24783 non-null  int64 \n",
            " 1   tweet   24783 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 580.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in data['tweet'].head(10).tolist():\n",
        "    print(i)\n",
        "    print('------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3IEOVQdjaca",
        "outputId": "9b7daf24-e68a-47fe-f57c-946429d762c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!!! RT @mayasolovely: As a woman you shouldn't complain about cleaning up your house. &amp; as a man you should always take the trash out...\n",
            "------------------------------------------------------\n",
            "!!!!! RT @mleew17: boy dats cold...tyga dwn bad for cuffin dat hoe in the 1st place!!\n",
            "------------------------------------------------------\n",
            "!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby4life: You ever fuck a bitch and she start to cry? You be confused as shit\n",
            "------------------------------------------------------\n",
            "!!!!!!!!! RT @C_G_Anderson: @viva_based she look like a tranny\n",
            "------------------------------------------------------\n",
            "!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you hear about me might be true or it might be faker than the bitch who told it to ya &#57361;\n",
            "------------------------------------------------------\n",
            "!!!!!!!!!!!!!!!!!!\"@T_Madison_x: The shit just blows me..claim you so faithful and down for somebody but still fucking with hoes! &#128514;&#128514;&#128514;\"\n",
            "------------------------------------------------------\n",
            "!!!!!!\"@__BrighterDays: I can not just sit up and HATE on another bitch .. I got too much shit going on!\"\n",
            "------------------------------------------------------\n",
            "!!!!&#8220;@selfiequeenbri: cause I'm tired of you big bitches coming for us skinny girls!!&#8221;\n",
            "------------------------------------------------------\n",
            "\" &amp; you might not get ya bitch back &amp; thats that \"\n",
            "------------------------------------------------------\n",
            "\" @rhythmixx_ :hobbies include: fighting Mariam\"\n",
            "\n",
            "bitch\n",
            "------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 0: hate speech, 1: offensive language, 2: neither\n",
        "data['class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lxugg6YAj1L0",
        "outputId": "7e520b14-c1d4-40b2-911c-d9df0036a016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    19190\n",
              "2     4163\n",
              "0     1430\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Preprocessing\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "def preprocess_text(tweet):\n",
        "    tweet = tweet.lower() #convert to lowercase\n",
        "    tweet = re.sub(r'^rt[\\s]+', '', tweet) #remove retweet\n",
        "    tweet = re.sub(' rt ', '', tweet) #remove retweet\n",
        "\n",
        "    tweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet) #remove hyperlink\n",
        "    tweet = re.sub(r'#', '', tweet) #remove hashtag\n",
        "    tweet = re.sub(r'[0-9]+', '', tweet) #remove numbers\n",
        "    tweet = re.sub(r'[^\\w\\s]', '', tweet) #remove punctuation\n",
        "\n",
        "    # return tweet\n",
        "\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [word for word in tweet.split() if word not in stop_words]\n",
        "\n",
        "    return ' '.join(words)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPogymR8j8yN",
        "outputId": "bceb5c96-45d0-473b-ea13-3270a740ccbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['cleaned_tweet'] = data['tweet'].apply(preprocess_text)"
      ],
      "metadata": {
        "id": "X2LM-kemnnis"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in data['cleaned_tweet'].head(10).tolist():\n",
        "    print(i)\n",
        "    print('---------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Jvzg5Uwnqsv",
        "outputId": "ec24a3ea-7568-4ac5-c97c-db525f5649de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mayasolovely woman shouldnt complain cleaning house amp man always take trash\n",
            "---------------------------------------------\n",
            "mleew boy dats coldtyga dwn bad cuffin dat hoe st place\n",
            "---------------------------------------------\n",
            "urkindofbrand dawgsbabylife ever fuck bitch start cry confused shit\n",
            "---------------------------------------------\n",
            "c_g_anderson viva_based look like tranny\n",
            "---------------------------------------------\n",
            "shenikaroberts shit hear might true might faker bitch told ya\n",
            "---------------------------------------------\n",
            "t_madison_x shit blows meclaim faithful somebody still fucking hoes\n",
            "---------------------------------------------\n",
            "__brighterdays sit hate another bitch got much shit going\n",
            "---------------------------------------------\n",
            "selfiequeenbri cause im tired big bitches coming us skinny girls\n",
            "---------------------------------------------\n",
            "amp might get ya bitch back amp thats\n",
            "---------------------------------------------\n",
            "rhythmixx_ hobbies include fighting mariam bitch\n",
            "---------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.sample(5000, random_state = 40)\n",
        "# data = data[:5000].reset_index()\n",
        "data = data.reset_index()\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GKsZygepoDSU",
        "outputId": "c5acd7f0-28cb-4347-9583-50afffd5dc3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   index  class                                              tweet  \\\n",
              "0  21823      1  That bitch called on Thor for some strength. &...   \n",
              "1  11160      1  I shoot at the pussy, I bust in the pussy I'm ...   \n",
              "2  19924      1  RT @lamessican: I love when bitches throw shad...   \n",
              "3  20360      2  RT @rickygervais: Humans are genetically close...   \n",
              "4  13633      1      Niggahs need to keep there bitches in check '   \n",
              "\n",
              "                                       cleaned_tweet  \n",
              "0    bitch called thor strength rtchubbygirlgod wait  \n",
              "1     shoot pussy bust pussy im cuming sooooooooooon  \n",
              "2  lamessican love bitches throw shade confirms i...  \n",
              "3  rickygervais humans genetically closer chimps ...  \n",
              "4                    niggahs need keep bitches check  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-70c4526c-d80c-44cf-9f7b-3c80ed3545d9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "      <th>cleaned_tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21823</td>\n",
              "      <td>1</td>\n",
              "      <td>That bitch called on Thor for some strength. &amp;...</td>\n",
              "      <td>bitch called thor strength rtchubbygirlgod wait</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11160</td>\n",
              "      <td>1</td>\n",
              "      <td>I shoot at the pussy, I bust in the pussy I'm ...</td>\n",
              "      <td>shoot pussy bust pussy im cuming sooooooooooon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19924</td>\n",
              "      <td>1</td>\n",
              "      <td>RT @lamessican: I love when bitches throw shad...</td>\n",
              "      <td>lamessican love bitches throw shade confirms i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>20360</td>\n",
              "      <td>2</td>\n",
              "      <td>RT @rickygervais: Humans are genetically close...</td>\n",
              "      <td>rickygervais humans genetically closer chimps ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13633</td>\n",
              "      <td>1</td>\n",
              "      <td>Niggahs need to keep there bitches in check '</td>\n",
              "      <td>niggahs need keep bitches check</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-70c4526c-d80c-44cf-9f7b-3c80ed3545d9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-70c4526c-d80c-44cf-9f7b-3c80ed3545d9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-70c4526c-d80c-44cf-9f7b-3c80ed3545d9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-2ef14fd4-c0ec-42c4-a31a-ea175b9c9ded\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-2ef14fd4-c0ec-42c4-a31a-ea175b9c9ded')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-2ef14fd4-c0ec-42c4-a31a-ea175b9c9ded button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['class'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPiOF6FmqzK6",
        "outputId": "ad7bae95-73a0-4ad4-e59d-cf37fba73750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    3857\n",
              "2     850\n",
              "0     293\n",
              "Name: class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, j in zip(data['cleaned_tweet'].head(10).tolist(), data['tweet'].head(10).tolist()):\n",
        "    print(i)\n",
        "    print('------------------------------------------------------')\n",
        "    print(j)\n",
        "    print('------------------------------------------------------')\n",
        "    print('------------------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJJ5kRLNq9Fz",
        "outputId": "316c471b-b2cb-4ec0-b364-7e335a312245"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bitch called thor strength rtchubbygirlgod wait\n",
            "------------------------------------------------------\n",
            "That bitch called on Thor for some strength. &#58386;&#58386; RT\"@ChubbyGirlGod: Wait... http://t.co/UAf57JyiOi\"\n",
            "------------------------------------------------------\n",
            "------------------------------------------------------\n",
            "shoot pussy bust pussy im cuming sooooooooooon\n",
            "------------------------------------------------------\n",
            "I shoot at the pussy, I bust in the pussy I'm cuming too sooooooooooon\n",
            "------------------------------------------------------\n",
            "------------------------------------------------------\n",
            "lamessican love bitches throw shade confirms im something right\n",
            "------------------------------------------------------\n",
            "RT @lamessican: I love when bitches throw shade. Just confirms i'm doing something right &#128514;\n",
            "------------------------------------------------------\n",
            "------------------------------------------------------\n",
            "rickygervais humans genetically closer chimps chimps gorillas apes great day clever twe\n",
            "------------------------------------------------------\n",
            "RT @rickygervais: Humans are genetically closer to chimps than chimps are to gorillas. But we are all apes. Have a great day you clever twe&#8230;\n",
            "------------------------------------------------------\n",
            "------------------------------------------------------\n",
            "niggahs need keep bitches check\n",
            "------------------------------------------------------\n",
            "Niggahs need to keep there bitches in check '\n",
            "------------------------------------------------------\n",
            "------------------------------------------------------\n",
            "kitlange stop oppressing heard free speech stop shoving lifestyle throat st amendment tcot teabaggers\n",
            "------------------------------------------------------\n",
            "@kitlange stop oppressing me! Have you heard of free speech? Stop shoving your lifestyle down my throat! 1st AMENDMENT! #tcot #teabaggers\n",
            "------------------------------------------------------\n",
            "------------------------------------------------------\n",
            "realniggasherm cant trust bitch cant trust\n",
            "------------------------------------------------------\n",
            "RT @RealNiggaSherm: I can't trust a bitch I can't trust myself\n",
            "------------------------------------------------------\n",
            "------------------------------------------------------\n",
            "fuck pussy ass hater go suck dick die quick someone youtube comments think wed good friends\n",
            "------------------------------------------------------\n",
            "\"fuck you you pussy ass hater go suck a dick and die quick\" - Someone, to me, in Youtube comments. I think we'd be good friends.\n",
            "------------------------------------------------------\n",
            "------------------------------------------------------\n",
            "stop spoiling u fags\n",
            "------------------------------------------------------\n",
            "Stop spoiling U fags\n",
            "------------------------------------------------------\n",
            "------------------------------------------------------\n",
            "juicygenie sheryl crow mom\n",
            "------------------------------------------------------\n",
            "RT @juicygenie: Sheryl crow be my mom\n",
            "------------------------------------------------------\n",
            "------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(data['cleaned_tweet'], data['class'], test_size=0.2, random_state=40)\n",
        "\n",
        "X_val = X_train[:int(len(X_train)*(1/8))]\n",
        "y_val = y_train[:int(len(y_train)*(1/8))]\n",
        "X_train = X_train[int(len(X_train)*(1/8)):]\n",
        "y_train = y_train[int(len(y_train)*(1/8)):]\n",
        "\n",
        "print(\"X_train shape: \", X_train.shape)\n",
        "print(\"y_train shape: \", y_train.shape)\n",
        "print(\"X_val shape: \", X_val.shape)\n",
        "print(\"y_val shape: \", y_val.shape)\n",
        "print(\"X_test shape: \", X_test.shape)\n",
        "print(\"y_test shape: \", y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCDQJ9IcrBrZ",
        "outputId": "06e30252-cf06-49f2-fcfc-5ef4ef27e8fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:  (3500,)\n",
            "y_train shape:  (3500,)\n",
            "X_val shape:  (500,)\n",
            "y_val shape:  (500,)\n",
            "X_test shape:  (1000,)\n",
            "y_test shape:  (1000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "\n",
        "import transformers\n",
        "from transformers import BertTokenizer"
      ],
      "metadata": {
        "id": "ErdxuhhbsJAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ycZcpGwslwX",
        "outputId": "1d5c9ac5-7847-4db2-8151-5c3f2bb8face"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "def tokenize_texts(texts):\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for text in texts:\n",
        "        encoded_text = tokenizer.encode_plus(\n",
        "            text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=32,\n",
        "            pad_to_max_length=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        input_ids.append(encoded_text['input_ids'])\n",
        "        attention_masks.append(encoded_text['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids, dim=0)\n",
        "    attention_masks = torch.cat(attention_masks, dim=0)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdxDauRCspnj",
        "outputId": "5b3ddea7-046d-4354-9b2c-442fa96ab2db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_input_ids, train_attention_masks = tokenize_texts(X_train)\n",
        "val_input_ids, val_attention_masks = tokenize_texts(X_val)\n",
        "test_input_ids, test_attention_masks = tokenize_texts(X_test)\n",
        "\n",
        "train_labels = torch.tensor(y_train.values)\n",
        "val_labels = torch.tensor(y_val.values)\n",
        "test_labels = torch.tensor(y_test.values)\n",
        "\n",
        "train_dataset = TensorDataset(train_input_ids, train_attention_masks, train_labels)\n",
        "val_dataset = TensorDataset(val_input_ids, val_attention_masks, val_labels)\n",
        "test_dataset = TensorDataset(test_input_ids, test_attention_masks, test_labels)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFgXJuDVt12R",
        "outputId": "99c7cd9b-7d3a-43ed-f5d0-869ef3e8b4e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextClassifierModel(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(TextClassifierModel, self).__init__()\n",
        "\n",
        "        self.bert = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        # freeze bert layers\n",
        "        # for param in self.bert.parameters():\n",
        "        #     param.requires_grad = False\n",
        "\n",
        "        self.cnn = nn.Conv1d(768, 256, kernel_size=3, padding=1)\n",
        "        self.bigru = nn.GRU(input_size=768, hidden_size=768, num_layers=2, bidirectional=True)\n",
        "\n",
        "        # Calculate the input size for the fully connected layer\n",
        "        fc_input_size = (256 + 2 * 768)*32\n",
        "\n",
        "        self.fc = nn.Linear(fc_input_size, 3)\n",
        "        # self.activation = nn.ReLU()  # You can use another activation function if needed\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        bert_output = bert_output.last_hidden_state.transpose(1, 2)\n",
        "\n",
        "        cnn_output = self.cnn(bert_output)\n",
        "        cnn_output = torch.flatten(cnn_output, start_dim=1)  # Flatten the CNN output\n",
        "\n",
        "        gru_output, _ = self.bigru(bert_output.permute(0, 2, 1))\n",
        "        gru_output = gru_output.permute(0, 2, 1)\n",
        "        gru_output = torch.flatten(gru_output, start_dim=1)  # Flatten the GRU output\n",
        "\n",
        "        cat_output = torch.cat((cnn_output, gru_output), dim=1)\n",
        "\n",
        "        final_output = self.fc(cat_output)\n",
        "        # final_output = self.activation(final_output)  # Apply activation function\n",
        "\n",
        "        return final_output"
      ],
      "metadata": {
        "id": "zca9Uzwa0Qfx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "model = TextClassifierModel()\n",
        "model = model.to(device)\n",
        "\n",
        "optim = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(5):\n",
        "    model.train()\n",
        "    i = 0\n",
        "    for batch in train_dataloader:\n",
        "        input_ids = batch[0].to(device)\n",
        "        attention_mask = batch[1].to(device)\n",
        "        labels = batch[2].to(device)\n",
        "\n",
        "        output = model(input_ids, attention_mask)\n",
        "\n",
        "        loss = loss_fn(output, labels)\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        optim.zero_grad()\n",
        "        print(i, \" Training Loss: \", loss)\n",
        "        i+=1\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        total_preds, total_labels = [], []\n",
        "        for batch in val_dataloader:\n",
        "            input_ids = batch[0].to(device)\n",
        "            attention_mask = batch[1].to(device)\n",
        "            labels = batch[2].to(device)\n",
        "            total_labels.append(labels.cpu().numpy())\n",
        "\n",
        "            output = model(input_ids, attention_mask)\n",
        "            loss = loss_fn(output, labels)\n",
        "            # print(\"Validation Loss: \", loss)\n",
        "\n",
        "            preds = torch.argmax(output, dim=1)\n",
        "            total_preds.append(preds.cpu().numpy())\n",
        "\n",
        "        total_labels, total_preds = np.concatenate(total_labels), np.concatenate(total_preds)\n",
        "        print(classification_report(total_labels, total_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiMddMVDv-wA",
        "outputId": "fde12e8b-f2d2-4b5b-d1ce-9cd5370a9c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0  Training Loss:  tensor(1.0425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "1  Training Loss:  tensor(0.7755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "2  Training Loss:  tensor(0.7145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "3  Training Loss:  tensor(0.3828, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "4  Training Loss:  tensor(0.8021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "5  Training Loss:  tensor(1.5612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "6  Training Loss:  tensor(0.8675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "7  Training Loss:  tensor(0.8361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "8  Training Loss:  tensor(0.1883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "9  Training Loss:  tensor(0.1523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "10  Training Loss:  tensor(0.4611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "11  Training Loss:  tensor(0.4215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "12  Training Loss:  tensor(1.4138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "13  Training Loss:  tensor(1.7666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "14  Training Loss:  tensor(0.1597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "15  Training Loss:  tensor(0.4668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "16  Training Loss:  tensor(1.2035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "17  Training Loss:  tensor(0.7040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "18  Training Loss:  tensor(0.4935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "19  Training Loss:  tensor(0.6390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "20  Training Loss:  tensor(0.5046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "21  Training Loss:  tensor(0.8593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "22  Training Loss:  tensor(0.5550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "23  Training Loss:  tensor(0.9171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "24  Training Loss:  tensor(0.6516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "25  Training Loss:  tensor(0.9244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "26  Training Loss:  tensor(0.4205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "27  Training Loss:  tensor(0.7602, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "28  Training Loss:  tensor(0.5229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "29  Training Loss:  tensor(0.5643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "30  Training Loss:  tensor(0.7030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "31  Training Loss:  tensor(1.4194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "32  Training Loss:  tensor(0.6606, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "33  Training Loss:  tensor(0.3745, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "34  Training Loss:  tensor(0.1775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "35  Training Loss:  tensor(0.4671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "36  Training Loss:  tensor(0.3760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "37  Training Loss:  tensor(1.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "38  Training Loss:  tensor(0.4212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "39  Training Loss:  tensor(0.4156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "40  Training Loss:  tensor(0.9418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "41  Training Loss:  tensor(0.4124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "42  Training Loss:  tensor(1.0299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "43  Training Loss:  tensor(1.0763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "44  Training Loss:  tensor(0.4383, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "45  Training Loss:  tensor(0.1625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "46  Training Loss:  tensor(0.8614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "47  Training Loss:  tensor(0.6603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "48  Training Loss:  tensor(0.4949, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "49  Training Loss:  tensor(0.6721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "50  Training Loss:  tensor(0.4435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "51  Training Loss:  tensor(0.5365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "52  Training Loss:  tensor(0.6897, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "53  Training Loss:  tensor(0.1932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "54  Training Loss:  tensor(0.1414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "55  Training Loss:  tensor(0.6341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "56  Training Loss:  tensor(0.8226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "57  Training Loss:  tensor(0.8342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "58  Training Loss:  tensor(0.4298, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "59  Training Loss:  tensor(0.3604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "60  Training Loss:  tensor(0.5825, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "61  Training Loss:  tensor(0.6221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "62  Training Loss:  tensor(0.4173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "63  Training Loss:  tensor(0.3573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "64  Training Loss:  tensor(0.3536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "65  Training Loss:  tensor(0.2582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "66  Training Loss:  tensor(0.5177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "67  Training Loss:  tensor(0.8300, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "68  Training Loss:  tensor(0.7072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "69  Training Loss:  tensor(0.6916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "70  Training Loss:  tensor(0.1128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "71  Training Loss:  tensor(0.3265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "72  Training Loss:  tensor(0.0427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "73  Training Loss:  tensor(0.8341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "74  Training Loss:  tensor(0.7056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "75  Training Loss:  tensor(0.7962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "76  Training Loss:  tensor(0.4520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "77  Training Loss:  tensor(0.4610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "78  Training Loss:  tensor(0.5196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "79  Training Loss:  tensor(0.3364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "80  Training Loss:  tensor(0.4943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "81  Training Loss:  tensor(0.4952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "82  Training Loss:  tensor(0.7399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "83  Training Loss:  tensor(0.4665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "84  Training Loss:  tensor(1.2668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "85  Training Loss:  tensor(0.3051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "86  Training Loss:  tensor(0.7561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "87  Training Loss:  tensor(0.2721, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "88  Training Loss:  tensor(0.8274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "89  Training Loss:  tensor(0.7809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "90  Training Loss:  tensor(0.5724, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "91  Training Loss:  tensor(1.0584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "92  Training Loss:  tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "93  Training Loss:  tensor(0.3030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "94  Training Loss:  tensor(0.2834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "95  Training Loss:  tensor(0.4470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "96  Training Loss:  tensor(0.8204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "97  Training Loss:  tensor(0.5679, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "98  Training Loss:  tensor(0.4099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "99  Training Loss:  tensor(0.7708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100  Training Loss:  tensor(0.6385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "101  Training Loss:  tensor(0.4437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "102  Training Loss:  tensor(0.6009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "103  Training Loss:  tensor(0.3125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "104  Training Loss:  tensor(0.9462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "105  Training Loss:  tensor(0.5023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "106  Training Loss:  tensor(0.3910, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "107  Training Loss:  tensor(0.3852, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "108  Training Loss:  tensor(0.6418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "109  Training Loss:  tensor(0.4651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "110  Training Loss:  tensor(0.6600, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "111  Training Loss:  tensor(0.6677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "112  Training Loss:  tensor(0.2588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "113  Training Loss:  tensor(0.6297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "114  Training Loss:  tensor(0.1960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "115  Training Loss:  tensor(0.7074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "116  Training Loss:  tensor(0.2808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "117  Training Loss:  tensor(0.4087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "118  Training Loss:  tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "119  Training Loss:  tensor(0.3545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "120  Training Loss:  tensor(0.4152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "121  Training Loss:  tensor(0.1136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "122  Training Loss:  tensor(0.2180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "123  Training Loss:  tensor(0.2217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "124  Training Loss:  tensor(0.1618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "125  Training Loss:  tensor(0.1261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "126  Training Loss:  tensor(0.0522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "127  Training Loss:  tensor(0.4718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "128  Training Loss:  tensor(0.2315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "129  Training Loss:  tensor(0.6172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "130  Training Loss:  tensor(0.2952, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "131  Training Loss:  tensor(0.9945, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "132  Training Loss:  tensor(0.1790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "133  Training Loss:  tensor(0.5961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "134  Training Loss:  tensor(0.1500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "135  Training Loss:  tensor(0.5715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "136  Training Loss:  tensor(0.2591, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "137  Training Loss:  tensor(0.7650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "138  Training Loss:  tensor(0.7761, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "139  Training Loss:  tensor(0.1255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "140  Training Loss:  tensor(0.3991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "141  Training Loss:  tensor(0.6157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "142  Training Loss:  tensor(0.4914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "143  Training Loss:  tensor(0.1653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "144  Training Loss:  tensor(0.3860, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "145  Training Loss:  tensor(0.3960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "146  Training Loss:  tensor(0.4854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "147  Training Loss:  tensor(0.4419, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "148  Training Loss:  tensor(0.3592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "149  Training Loss:  tensor(0.3019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "150  Training Loss:  tensor(0.1193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "151  Training Loss:  tensor(0.2947, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "152  Training Loss:  tensor(0.4404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "153  Training Loss:  tensor(0.8581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "154  Training Loss:  tensor(0.1203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "155  Training Loss:  tensor(0.4719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "156  Training Loss:  tensor(1.1616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "157  Training Loss:  tensor(0.3637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "158  Training Loss:  tensor(0.0213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "159  Training Loss:  tensor(0.2222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "160  Training Loss:  tensor(0.2517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "161  Training Loss:  tensor(0.7075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "162  Training Loss:  tensor(0.3366, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "163  Training Loss:  tensor(0.7254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "164  Training Loss:  tensor(0.2865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "165  Training Loss:  tensor(0.3512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "166  Training Loss:  tensor(0.2750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "167  Training Loss:  tensor(0.2883, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "168  Training Loss:  tensor(0.0417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "169  Training Loss:  tensor(0.1579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "170  Training Loss:  tensor(1.4257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "171  Training Loss:  tensor(0.6656, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "172  Training Loss:  tensor(0.2115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "173  Training Loss:  tensor(0.1182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "174  Training Loss:  tensor(0.5328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "175  Training Loss:  tensor(0.1009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "176  Training Loss:  tensor(0.2359, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "177  Training Loss:  tensor(0.0977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "178  Training Loss:  tensor(1.0470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "179  Training Loss:  tensor(0.1175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "180  Training Loss:  tensor(0.1117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "181  Training Loss:  tensor(0.5135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "182  Training Loss:  tensor(0.4693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "183  Training Loss:  tensor(0.1725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "184  Training Loss:  tensor(0.3711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "185  Training Loss:  tensor(0.1869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "186  Training Loss:  tensor(0.0628, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "187  Training Loss:  tensor(0.4763, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "188  Training Loss:  tensor(0.3244, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "189  Training Loss:  tensor(0.4247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "190  Training Loss:  tensor(0.6292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "191  Training Loss:  tensor(0.3280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "192  Training Loss:  tensor(0.2622, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "193  Training Loss:  tensor(0.9044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "194  Training Loss:  tensor(1.1570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "195  Training Loss:  tensor(0.7803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "196  Training Loss:  tensor(0.4434, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "197  Training Loss:  tensor(0.5422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "198  Training Loss:  tensor(0.3408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "199  Training Loss:  tensor(0.4659, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "200  Training Loss:  tensor(0.2818, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "201  Training Loss:  tensor(0.2575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "202  Training Loss:  tensor(0.2107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "203  Training Loss:  tensor(0.2714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "204  Training Loss:  tensor(0.4067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "205  Training Loss:  tensor(0.2180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "206  Training Loss:  tensor(0.1258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "207  Training Loss:  tensor(0.5750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "208  Training Loss:  tensor(0.7346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "209  Training Loss:  tensor(0.1177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "210  Training Loss:  tensor(1.1003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "211  Training Loss:  tensor(0.4841, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "212  Training Loss:  tensor(0.4572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "213  Training Loss:  tensor(0.3636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "214  Training Loss:  tensor(0.0859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "215  Training Loss:  tensor(0.3246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "216  Training Loss:  tensor(0.1208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "217  Training Loss:  tensor(0.2414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "218  Training Loss:  tensor(0.0898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "219  Training Loss:  tensor(0.4736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "220  Training Loss:  tensor(0.6906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "221  Training Loss:  tensor(0.4581, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "222  Training Loss:  tensor(0.5192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "223  Training Loss:  tensor(0.3081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "224  Training Loss:  tensor(0.3838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "225  Training Loss:  tensor(0.4378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "226  Training Loss:  tensor(0.2517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "227  Training Loss:  tensor(0.2859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "228  Training Loss:  tensor(0.3245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "229  Training Loss:  tensor(0.3340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "230  Training Loss:  tensor(0.1417, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "231  Training Loss:  tensor(0.0550, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "232  Training Loss:  tensor(0.2516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "233  Training Loss:  tensor(0.0271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "234  Training Loss:  tensor(0.6981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "235  Training Loss:  tensor(0.2722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "236  Training Loss:  tensor(0.0623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "237  Training Loss:  tensor(0.6816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "238  Training Loss:  tensor(0.3673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "239  Training Loss:  tensor(0.3562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "240  Training Loss:  tensor(0.7155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "241  Training Loss:  tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "242  Training Loss:  tensor(0.1907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "243  Training Loss:  tensor(0.2633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "244  Training Loss:  tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "245  Training Loss:  tensor(0.3715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "246  Training Loss:  tensor(0.5151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "247  Training Loss:  tensor(0.7390, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "248  Training Loss:  tensor(0.7386, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "249  Training Loss:  tensor(1.4742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "250  Training Loss:  tensor(0.1954, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "251  Training Loss:  tensor(0.0998, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "252  Training Loss:  tensor(0.1377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "253  Training Loss:  tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "254  Training Loss:  tensor(0.0930, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "255  Training Loss:  tensor(0.2932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "256  Training Loss:  tensor(0.0468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "257  Training Loss:  tensor(1.1530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "258  Training Loss:  tensor(0.4881, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "259  Training Loss:  tensor(0.0811, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "260  Training Loss:  tensor(0.4285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "261  Training Loss:  tensor(0.5468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "262  Training Loss:  tensor(0.3079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "263  Training Loss:  tensor(0.3398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "264  Training Loss:  tensor(0.3833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "265  Training Loss:  tensor(0.3872, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "266  Training Loss:  tensor(0.6262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "267  Training Loss:  tensor(0.6853, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "268  Training Loss:  tensor(0.2483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "269  Training Loss:  tensor(0.3301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "270  Training Loss:  tensor(0.3512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "271  Training Loss:  tensor(0.1966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "272  Training Loss:  tensor(0.2242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "273  Training Loss:  tensor(0.1113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "274  Training Loss:  tensor(0.5735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "275  Training Loss:  tensor(0.2328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "276  Training Loss:  tensor(0.0812, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "277  Training Loss:  tensor(0.4477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "278  Training Loss:  tensor(0.1284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "279  Training Loss:  tensor(0.5655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "280  Training Loss:  tensor(0.3722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "281  Training Loss:  tensor(0.5667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "282  Training Loss:  tensor(0.2579, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "283  Training Loss:  tensor(0.0319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "284  Training Loss:  tensor(0.1657, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "285  Training Loss:  tensor(0.6085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "286  Training Loss:  tensor(0.0789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "287  Training Loss:  tensor(0.4203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "288  Training Loss:  tensor(0.2238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "289  Training Loss:  tensor(0.2862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "290  Training Loss:  tensor(0.3845, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "291  Training Loss:  tensor(0.2433, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "292  Training Loss:  tensor(0.0706, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "293  Training Loss:  tensor(0.2510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "294  Training Loss:  tensor(0.5986, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "295  Training Loss:  tensor(0.0851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "296  Training Loss:  tensor(0.1021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "297  Training Loss:  tensor(0.1781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "298  Training Loss:  tensor(0.1495, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "299  Training Loss:  tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "300  Training Loss:  tensor(0.2101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "301  Training Loss:  tensor(0.6170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "302  Training Loss:  tensor(0.0294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "303  Training Loss:  tensor(0.3468, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "304  Training Loss:  tensor(0.4060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "305  Training Loss:  tensor(0.3514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "306  Training Loss:  tensor(0.0915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "307  Training Loss:  tensor(0.7123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "308  Training Loss:  tensor(0.0951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "309  Training Loss:  tensor(0.0505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "310  Training Loss:  tensor(0.9555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "311  Training Loss:  tensor(0.2309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "312  Training Loss:  tensor(0.3735, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "313  Training Loss:  tensor(0.0324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "314  Training Loss:  tensor(0.0306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "315  Training Loss:  tensor(0.0297, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "316  Training Loss:  tensor(1.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "317  Training Loss:  tensor(0.0985, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "318  Training Loss:  tensor(0.0655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "319  Training Loss:  tensor(0.3738, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "320  Training Loss:  tensor(0.6895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "321  Training Loss:  tensor(0.4052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "322  Training Loss:  tensor(0.1887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "323  Training Loss:  tensor(0.0354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "324  Training Loss:  tensor(0.4977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "325  Training Loss:  tensor(0.0189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "326  Training Loss:  tensor(0.4033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "327  Training Loss:  tensor(0.0160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "328  Training Loss:  tensor(0.2238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "329  Training Loss:  tensor(0.1319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "330  Training Loss:  tensor(0.2855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "331  Training Loss:  tensor(0.1271, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "332  Training Loss:  tensor(0.3630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "333  Training Loss:  tensor(0.5198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "334  Training Loss:  tensor(0.8898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "335  Training Loss:  tensor(0.1773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "336  Training Loss:  tensor(0.7748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "337  Training Loss:  tensor(0.0193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "338  Training Loss:  tensor(0.2148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "339  Training Loss:  tensor(0.2236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "340  Training Loss:  tensor(0.5329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "341  Training Loss:  tensor(0.2082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "342  Training Loss:  tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "343  Training Loss:  tensor(0.8568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "344  Training Loss:  tensor(0.3684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "345  Training Loss:  tensor(0.0907, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "346  Training Loss:  tensor(0.5984, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "347  Training Loss:  tensor(0.0653, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "348  Training Loss:  tensor(0.1660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "349  Training Loss:  tensor(0.5660, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "350  Training Loss:  tensor(0.9517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "351  Training Loss:  tensor(0.1662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "352  Training Loss:  tensor(0.0808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "353  Training Loss:  tensor(0.2851, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "354  Training Loss:  tensor(0.5428, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "355  Training Loss:  tensor(0.3179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "356  Training Loss:  tensor(0.6284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "357  Training Loss:  tensor(0.0704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "358  Training Loss:  tensor(0.6781, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "359  Training Loss:  tensor(0.2993, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "360  Training Loss:  tensor(0.2043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "361  Training Loss:  tensor(0.8262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "362  Training Loss:  tensor(0.1253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "363  Training Loss:  tensor(0.4794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "364  Training Loss:  tensor(0.2286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "365  Training Loss:  tensor(0.6146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "366  Training Loss:  tensor(0.6190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "367  Training Loss:  tensor(0.4413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "368  Training Loss:  tensor(0.3112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "369  Training Loss:  tensor(1.1965, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "370  Training Loss:  tensor(0.2182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "371  Training Loss:  tensor(0.2426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "372  Training Loss:  tensor(0.1567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "373  Training Loss:  tensor(0.1726, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "374  Training Loss:  tensor(0.1842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "375  Training Loss:  tensor(0.3276, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "376  Training Loss:  tensor(0.6769, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "377  Training Loss:  tensor(0.1315, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "378  Training Loss:  tensor(0.5612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "379  Training Loss:  tensor(0.1288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "380  Training Loss:  tensor(0.3838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "381  Training Loss:  tensor(0.7093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "382  Training Loss:  tensor(0.3128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "383  Training Loss:  tensor(0.1502, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "384  Training Loss:  tensor(0.1281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "385  Training Loss:  tensor(0.1175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "386  Training Loss:  tensor(0.0982, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "387  Training Loss:  tensor(0.1856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "388  Training Loss:  tensor(0.0976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "389  Training Loss:  tensor(0.1334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "390  Training Loss:  tensor(0.1569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "391  Training Loss:  tensor(0.4522, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "392  Training Loss:  tensor(0.0451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "393  Training Loss:  tensor(0.4247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "394  Training Loss:  tensor(0.1611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "395  Training Loss:  tensor(0.1289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "396  Training Loss:  tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "397  Training Loss:  tensor(0.3588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "398  Training Loss:  tensor(0.0500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "399  Training Loss:  tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "400  Training Loss:  tensor(0.4399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "401  Training Loss:  tensor(0.8748, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "402  Training Loss:  tensor(0.7430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "403  Training Loss:  tensor(0.1155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "404  Training Loss:  tensor(0.1778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "405  Training Loss:  tensor(0.9418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "406  Training Loss:  tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "407  Training Loss:  tensor(0.3617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "408  Training Loss:  tensor(0.3411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "409  Training Loss:  tensor(0.9438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "410  Training Loss:  tensor(0.0545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "411  Training Loss:  tensor(0.1536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "412  Training Loss:  tensor(0.2890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "413  Training Loss:  tensor(0.0540, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "414  Training Loss:  tensor(0.3678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "415  Training Loss:  tensor(0.3395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "416  Training Loss:  tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "417  Training Loss:  tensor(0.3007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "418  Training Loss:  tensor(0.0969, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "419  Training Loss:  tensor(0.5104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "420  Training Loss:  tensor(0.0636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "421  Training Loss:  tensor(0.0711, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "422  Training Loss:  tensor(0.0625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "423  Training Loss:  tensor(0.1174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "424  Training Loss:  tensor(0.1966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "425  Training Loss:  tensor(0.2610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "426  Training Loss:  tensor(0.0303, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "427  Training Loss:  tensor(0.0326, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "428  Training Loss:  tensor(0.5610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "429  Training Loss:  tensor(0.1934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "430  Training Loss:  tensor(0.5682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "431  Training Loss:  tensor(0.1154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "432  Training Loss:  tensor(1.0915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "433  Training Loss:  tensor(0.1627, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "434  Training Loss:  tensor(0.0233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "435  Training Loss:  tensor(0.0499, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "436  Training Loss:  tensor(0.2103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "437  Training Loss:  tensor(0.3142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.15      0.23        27\n",
            "           1       0.94      0.96      0.95       381\n",
            "           2       0.82      0.93      0.87        92\n",
            "\n",
            "    accuracy                           0.91       500\n",
            "   macro avg       0.75      0.68      0.68       500\n",
            "weighted avg       0.90      0.91      0.90       500\n",
            "\n",
            "0  Training Loss:  tensor(0.6491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "1  Training Loss:  tensor(0.0498, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "2  Training Loss:  tensor(0.0898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "3  Training Loss:  tensor(0.1471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "4  Training Loss:  tensor(0.1286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "5  Training Loss:  tensor(0.5494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "6  Training Loss:  tensor(0.3088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "7  Training Loss:  tensor(0.5943, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "8  Training Loss:  tensor(0.2402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "9  Training Loss:  tensor(0.1140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "10  Training Loss:  tensor(0.5061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "11  Training Loss:  tensor(0.0832, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "12  Training Loss:  tensor(0.1783, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "13  Training Loss:  tensor(0.4042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "14  Training Loss:  tensor(0.1586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "15  Training Loss:  tensor(0.1637, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "16  Training Loss:  tensor(0.0840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "17  Training Loss:  tensor(0.0489, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "18  Training Loss:  tensor(0.5560, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "19  Training Loss:  tensor(0.1946, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "20  Training Loss:  tensor(0.2212, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "21  Training Loss:  tensor(0.7641, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "22  Training Loss:  tensor(0.6278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "23  Training Loss:  tensor(0.9874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "24  Training Loss:  tensor(0.0675, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "25  Training Loss:  tensor(0.1264, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "26  Training Loss:  tensor(0.9347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "27  Training Loss:  tensor(0.2815, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "28  Training Loss:  tensor(0.0304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "29  Training Loss:  tensor(0.3692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "30  Training Loss:  tensor(0.0379, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "31  Training Loss:  tensor(0.5041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "32  Training Loss:  tensor(0.4616, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "33  Training Loss:  tensor(0.8962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "34  Training Loss:  tensor(0.1092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "35  Training Loss:  tensor(0.0929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "36  Training Loss:  tensor(0.1521, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "37  Training Loss:  tensor(0.1929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "38  Training Loss:  tensor(0.0587, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "39  Training Loss:  tensor(0.1414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "40  Training Loss:  tensor(0.0736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "41  Training Loss:  tensor(0.0752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "42  Training Loss:  tensor(0.4277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "43  Training Loss:  tensor(0.0680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "44  Training Loss:  tensor(0.2737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "45  Training Loss:  tensor(0.0630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "46  Training Loss:  tensor(0.0283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "47  Training Loss:  tensor(0.3607, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "48  Training Loss:  tensor(0.2538, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "49  Training Loss:  tensor(0.5239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "50  Training Loss:  tensor(0.2578, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "51  Training Loss:  tensor(0.3621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "52  Training Loss:  tensor(0.6109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "53  Training Loss:  tensor(0.4576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "54  Training Loss:  tensor(0.0447, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "55  Training Loss:  tensor(0.2097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "56  Training Loss:  tensor(0.0267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "57  Training Loss:  tensor(0.1736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "58  Training Loss:  tensor(0.8506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "59  Training Loss:  tensor(0.0874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "60  Training Loss:  tensor(0.1257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "61  Training Loss:  tensor(0.2125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "62  Training Loss:  tensor(0.1394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "63  Training Loss:  tensor(0.1574, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "64  Training Loss:  tensor(0.2192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "65  Training Loss:  tensor(0.0834, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "66  Training Loss:  tensor(0.5126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "67  Training Loss:  tensor(0.1050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "68  Training Loss:  tensor(0.5056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "69  Training Loss:  tensor(0.1170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "70  Training Loss:  tensor(0.2333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "71  Training Loss:  tensor(0.2548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "72  Training Loss:  tensor(0.2808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "73  Training Loss:  tensor(0.3963, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "74  Training Loss:  tensor(0.0387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "75  Training Loss:  tensor(0.0669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "76  Training Loss:  tensor(0.5516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "77  Training Loss:  tensor(0.0846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "78  Training Loss:  tensor(0.2288, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "79  Training Loss:  tensor(0.1045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "80  Training Loss:  tensor(0.0481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "81  Training Loss:  tensor(0.1817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "82  Training Loss:  tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "83  Training Loss:  tensor(0.1722, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "84  Training Loss:  tensor(0.1481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "85  Training Loss:  tensor(0.0246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "86  Training Loss:  tensor(0.1482, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "87  Training Loss:  tensor(0.8824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "88  Training Loss:  tensor(0.2934, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "89  Training Loss:  tensor(0.1583, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "90  Training Loss:  tensor(0.5671, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "91  Training Loss:  tensor(0.2051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "92  Training Loss:  tensor(0.6253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "93  Training Loss:  tensor(0.0898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "94  Training Loss:  tensor(0.0464, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "95  Training Loss:  tensor(0.1445, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "96  Training Loss:  tensor(0.0859, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "97  Training Loss:  tensor(0.4523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "98  Training Loss:  tensor(0.1708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "99  Training Loss:  tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100  Training Loss:  tensor(0.3785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "101  Training Loss:  tensor(0.2826, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "102  Training Loss:  tensor(0.0456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "103  Training Loss:  tensor(0.2067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "104  Training Loss:  tensor(0.3491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "105  Training Loss:  tensor(0.0277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "106  Training Loss:  tensor(0.1427, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "107  Training Loss:  tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "108  Training Loss:  tensor(0.4808, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "109  Training Loss:  tensor(0.1269, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "110  Training Loss:  tensor(0.0833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "111  Training Loss:  tensor(0.4463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "112  Training Loss:  tensor(0.6568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "113  Training Loss:  tensor(0.4758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "114  Training Loss:  tensor(0.0418, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "115  Training Loss:  tensor(0.1610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "116  Training Loss:  tensor(0.1506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "117  Training Loss:  tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "118  Training Loss:  tensor(0.5095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "119  Training Loss:  tensor(0.1964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "120  Training Loss:  tensor(0.2689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "121  Training Loss:  tensor(0.0391, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "122  Training Loss:  tensor(0.1052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "123  Training Loss:  tensor(0.4964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "124  Training Loss:  tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "125  Training Loss:  tensor(0.0736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "126  Training Loss:  tensor(0.2516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "127  Training Loss:  tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "128  Training Loss:  tensor(0.0134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "129  Training Loss:  tensor(0.0165, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "130  Training Loss:  tensor(0.6617, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "131  Training Loss:  tensor(0.0243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "132  Training Loss:  tensor(0.0472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "133  Training Loss:  tensor(0.6789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "134  Training Loss:  tensor(1.3494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "135  Training Loss:  tensor(1.6680, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "136  Training Loss:  tensor(0.3867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "137  Training Loss:  tensor(0.4252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "138  Training Loss:  tensor(0.4192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "139  Training Loss:  tensor(0.3072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "140  Training Loss:  tensor(0.0633, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "141  Training Loss:  tensor(0.4048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "142  Training Loss:  tensor(0.3842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "143  Training Loss:  tensor(0.2505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "144  Training Loss:  tensor(0.2197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "145  Training Loss:  tensor(0.1199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "146  Training Loss:  tensor(0.0989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "147  Training Loss:  tensor(0.4528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "148  Training Loss:  tensor(0.3615, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "149  Training Loss:  tensor(0.1686, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "150  Training Loss:  tensor(0.4340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "151  Training Loss:  tensor(0.3344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "152  Training Loss:  tensor(0.3678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "153  Training Loss:  tensor(0.6772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "154  Training Loss:  tensor(0.2152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "155  Training Loss:  tensor(0.4571, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "156  Training Loss:  tensor(0.2157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "157  Training Loss:  tensor(0.0960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "158  Training Loss:  tensor(0.1250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "159  Training Loss:  tensor(0.5285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "160  Training Loss:  tensor(0.0855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "161  Training Loss:  tensor(0.0778, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "162  Training Loss:  tensor(0.1198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "163  Training Loss:  tensor(0.1585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "164  Training Loss:  tensor(0.0322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "165  Training Loss:  tensor(0.2222, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "166  Training Loss:  tensor(0.3864, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "167  Training Loss:  tensor(0.1512, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "168  Training Loss:  tensor(0.1122, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "169  Training Loss:  tensor(0.3229, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "170  Training Loss:  tensor(0.0211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "171  Training Loss:  tensor(0.1682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "172  Training Loss:  tensor(0.0647, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "173  Training Loss:  tensor(0.1051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "174  Training Loss:  tensor(0.1638, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "175  Training Loss:  tensor(0.2049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "176  Training Loss:  tensor(0.5060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "177  Training Loss:  tensor(0.0478, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "178  Training Loss:  tensor(0.0662, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "179  Training Loss:  tensor(0.0246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "180  Training Loss:  tensor(0.0105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "181  Training Loss:  tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "182  Training Loss:  tensor(0.0750, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "183  Training Loss:  tensor(0.8547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "184  Training Loss:  tensor(0.8731, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "185  Training Loss:  tensor(0.7283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "186  Training Loss:  tensor(0.1322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "187  Training Loss:  tensor(0.1402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "188  Training Loss:  tensor(0.0838, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "189  Training Loss:  tensor(0.0849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "190  Training Loss:  tensor(0.1609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "191  Training Loss:  tensor(0.2710, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "192  Training Loss:  tensor(0.1803, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "193  Training Loss:  tensor(0.0412, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "194  Training Loss:  tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "195  Training Loss:  tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "196  Training Loss:  tensor(0.1189, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "197  Training Loss:  tensor(0.8903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "198  Training Loss:  tensor(0.2858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "199  Training Loss:  tensor(0.2504, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "200  Training Loss:  tensor(0.0820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "201  Training Loss:  tensor(0.4972, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "202  Training Loss:  tensor(0.3190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "203  Training Loss:  tensor(0.1444, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "204  Training Loss:  tensor(0.3957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "205  Training Loss:  tensor(0.0350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "206  Training Loss:  tensor(0.2827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "207  Training Loss:  tensor(0.0920, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "208  Training Loss:  tensor(0.0558, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "209  Training Loss:  tensor(0.4914, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "210  Training Loss:  tensor(0.1599, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "211  Training Loss:  tensor(0.5045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "212  Training Loss:  tensor(0.2977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "213  Training Loss:  tensor(0.1329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "214  Training Loss:  tensor(0.3094, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "215  Training Loss:  tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "216  Training Loss:  tensor(0.1402, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "217  Training Loss:  tensor(0.0736, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "218  Training Loss:  tensor(0.6833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "219  Training Loss:  tensor(0.8909, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "220  Training Loss:  tensor(0.0827, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "221  Training Loss:  tensor(0.1923, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "222  Training Loss:  tensor(0.1931, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "223  Training Loss:  tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "224  Training Loss:  tensor(0.0282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "225  Training Loss:  tensor(0.0858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "226  Training Loss:  tensor(0.2354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "227  Training Loss:  tensor(0.4369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "228  Training Loss:  tensor(0.1935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "229  Training Loss:  tensor(0.1260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "230  Training Loss:  tensor(0.7216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "231  Training Loss:  tensor(0.1766, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "232  Training Loss:  tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "233  Training Loss:  tensor(0.2773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "234  Training Loss:  tensor(0.2337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "235  Training Loss:  tensor(0.3281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "236  Training Loss:  tensor(0.0265, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "237  Training Loss:  tensor(0.4339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "238  Training Loss:  tensor(0.1569, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "239  Training Loss:  tensor(0.2561, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "240  Training Loss:  tensor(0.4217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "241  Training Loss:  tensor(0.2077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "242  Training Loss:  tensor(0.7891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "243  Training Loss:  tensor(0.4966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "244  Training Loss:  tensor(0.5081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "245  Training Loss:  tensor(0.6093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "246  Training Loss:  tensor(0.0249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "247  Training Loss:  tensor(0.1117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "248  Training Loss:  tensor(0.3534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "249  Training Loss:  tensor(0.0743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "250  Training Loss:  tensor(0.0987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "251  Training Loss:  tensor(0.2809, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "252  Training Loss:  tensor(0.0413, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "253  Training Loss:  tensor(0.8437, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "254  Training Loss:  tensor(0.0882, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "255  Training Loss:  tensor(0.2088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "256  Training Loss:  tensor(0.1339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "257  Training Loss:  tensor(0.2951, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "258  Training Loss:  tensor(0.4214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "259  Training Loss:  tensor(0.2082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "260  Training Loss:  tensor(0.1562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "261  Training Loss:  tensor(0.0456, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "262  Training Loss:  tensor(0.0268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "263  Training Loss:  tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "264  Training Loss:  tensor(0.0871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "265  Training Loss:  tensor(0.1043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "266  Training Loss:  tensor(0.6465, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "267  Training Loss:  tensor(0.0147, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "268  Training Loss:  tensor(0.1837, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "269  Training Loss:  tensor(0.3435, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "270  Training Loss:  tensor(0.4580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "271  Training Loss:  tensor(0.1966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "272  Training Loss:  tensor(0.4162, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "273  Training Loss:  tensor(0.0237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "274  Training Loss:  tensor(0.6640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "275  Training Loss:  tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "276  Training Loss:  tensor(0.0842, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "277  Training Loss:  tensor(0.0568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "278  Training Loss:  tensor(0.1186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "279  Training Loss:  tensor(0.4562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "280  Training Loss:  tensor(0.0878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "281  Training Loss:  tensor(0.4438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "282  Training Loss:  tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "283  Training Loss:  tensor(0.0236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "284  Training Loss:  tensor(0.3296, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "285  Training Loss:  tensor(0.2101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "286  Training Loss:  tensor(0.0665, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "287  Training Loss:  tensor(0.1088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "288  Training Loss:  tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "289  Training Loss:  tensor(0.0281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "290  Training Loss:  tensor(0.3151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "291  Training Loss:  tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "292  Training Loss:  tensor(0.1737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "293  Training Loss:  tensor(0.0479, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "294  Training Loss:  tensor(0.6237, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "295  Training Loss:  tensor(0.3312, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "296  Training Loss:  tensor(0.1645, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "297  Training Loss:  tensor(0.0103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "298  Training Loss:  tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "299  Training Loss:  tensor(0.0743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "300  Training Loss:  tensor(0.1333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "301  Training Loss:  tensor(0.0989, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "302  Training Loss:  tensor(0.1051, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "303  Training Loss:  tensor(0.0343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "304  Training Loss:  tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "305  Training Loss:  tensor(0.6584, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "306  Training Loss:  tensor(0.0890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "307  Training Loss:  tensor(1.0877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "308  Training Loss:  tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "309  Training Loss:  tensor(0.0730, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "310  Training Loss:  tensor(0.0294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "311  Training Loss:  tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "312  Training Loss:  tensor(0.1624, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "313  Training Loss:  tensor(0.2353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "314  Training Loss:  tensor(0.2180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "315  Training Loss:  tensor(0.0789, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "316  Training Loss:  tensor(0.2517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "317  Training Loss:  tensor(0.3682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "318  Training Loss:  tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "319  Training Loss:  tensor(0.4093, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "320  Training Loss:  tensor(0.4332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "321  Training Loss:  tensor(0.5000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "322  Training Loss:  tensor(0.8990, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "323  Training Loss:  tensor(0.0805, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "324  Training Loss:  tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "325  Training Loss:  tensor(0.1636, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "326  Training Loss:  tensor(0.0682, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "327  Training Loss:  tensor(0.6743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "328  Training Loss:  tensor(0.8174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "329  Training Loss:  tensor(0.1425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "330  Training Loss:  tensor(0.1528, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "331  Training Loss:  tensor(0.0282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "332  Training Loss:  tensor(0.0545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "333  Training Loss:  tensor(0.0518, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "334  Training Loss:  tensor(0.4153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "335  Training Loss:  tensor(0.3684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "336  Training Loss:  tensor(0.3481, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "337  Training Loss:  tensor(0.1155, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "338  Training Loss:  tensor(0.8648, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "339  Training Loss:  tensor(0.0692, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "340  Training Loss:  tensor(0.0752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "341  Training Loss:  tensor(0.1800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "342  Training Loss:  tensor(0.2424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "343  Training Loss:  tensor(0.5128, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "344  Training Loss:  tensor(0.6775, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "345  Training Loss:  tensor(0.1043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "346  Training Loss:  tensor(0.4592, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "347  Training Loss:  tensor(0.1240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "348  Training Loss:  tensor(0.3810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "349  Training Loss:  tensor(0.5322, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "350  Training Loss:  tensor(0.1643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "351  Training Loss:  tensor(0.0893, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "352  Training Loss:  tensor(0.2936, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "353  Training Loss:  tensor(0.2596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "354  Training Loss:  tensor(0.4284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "355  Training Loss:  tensor(0.1135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "356  Training Loss:  tensor(0.3329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "357  Training Loss:  tensor(0.8713, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "358  Training Loss:  tensor(0.1895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "359  Training Loss:  tensor(0.0958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "360  Training Loss:  tensor(0.1188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "361  Training Loss:  tensor(0.2632, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "362  Training Loss:  tensor(0.3782, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "363  Training Loss:  tensor(0.0596, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "364  Training Loss:  tensor(0.2193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "365  Training Loss:  tensor(0.4764, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "366  Training Loss:  tensor(0.3668, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "367  Training Loss:  tensor(0.4270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "368  Training Loss:  tensor(0.1441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "369  Training Loss:  tensor(0.2183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "370  Training Loss:  tensor(0.2568, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "371  Training Loss:  tensor(0.1884, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "372  Training Loss:  tensor(0.2161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "373  Training Loss:  tensor(0.1830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "374  Training Loss:  tensor(0.2141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "375  Training Loss:  tensor(0.1109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "376  Training Loss:  tensor(0.1799, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "377  Training Loss:  tensor(0.0411, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "378  Training Loss:  tensor(0.4008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "379  Training Loss:  tensor(0.8453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "380  Training Loss:  tensor(0.3022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "381  Training Loss:  tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "382  Training Loss:  tensor(0.2462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "383  Training Loss:  tensor(1.0673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "384  Training Loss:  tensor(0.1492, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "385  Training Loss:  tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "386  Training Loss:  tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "387  Training Loss:  tensor(0.5257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "388  Training Loss:  tensor(0.4060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "389  Training Loss:  tensor(0.0669, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "390  Training Loss:  tensor(0.3430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "391  Training Loss:  tensor(0.0173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "392  Training Loss:  tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "393  Training Loss:  tensor(0.4129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "394  Training Loss:  tensor(0.2658, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "395  Training Loss:  tensor(0.1773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "396  Training Loss:  tensor(0.1233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "397  Training Loss:  tensor(0.0980, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "398  Training Loss:  tensor(0.4878, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "399  Training Loss:  tensor(0.8074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "400  Training Loss:  tensor(0.1254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "401  Training Loss:  tensor(0.1597, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "402  Training Loss:  tensor(0.0572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "403  Training Loss:  tensor(0.7107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "404  Training Loss:  tensor(0.0650, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "405  Training Loss:  tensor(0.0342, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "406  Training Loss:  tensor(0.1089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "407  Training Loss:  tensor(0.0310, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "408  Training Loss:  tensor(0.3773, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "409  Training Loss:  tensor(0.0543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "410  Training Loss:  tensor(0.0896, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "411  Training Loss:  tensor(0.1889, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "412  Training Loss:  tensor(0.1144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "413  Training Loss:  tensor(0.1079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "414  Training Loss:  tensor(0.3892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "415  Training Loss:  tensor(0.0483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "416  Training Loss:  tensor(0.0387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "417  Training Loss:  tensor(0.7966, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "418  Training Loss:  tensor(0.0425, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "419  Training Loss:  tensor(0.0205, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "420  Training Loss:  tensor(0.2994, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "421  Training Loss:  tensor(0.1202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "422  Training Loss:  tensor(0.2304, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "423  Training Loss:  tensor(0.8026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "424  Training Loss:  tensor(0.0644, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "425  Training Loss:  tensor(0.3060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "426  Training Loss:  tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "427  Training Loss:  tensor(0.0505, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "428  Training Loss:  tensor(0.3981, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "429  Training Loss:  tensor(0.0758, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "430  Training Loss:  tensor(0.2663, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "431  Training Loss:  tensor(0.3211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "432  Training Loss:  tensor(0.1301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "433  Training Loss:  tensor(0.1604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "434  Training Loss:  tensor(0.2858, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "435  Training Loss:  tensor(0.6180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "436  Training Loss:  tensor(0.0258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "437  Training Loss:  tensor(0.0367, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.58      0.41      0.48        27\n",
            "           1       0.96      0.95      0.95       381\n",
            "           2       0.85      0.96      0.90        92\n",
            "\n",
            "    accuracy                           0.92       500\n",
            "   macro avg       0.80      0.77      0.78       500\n",
            "weighted avg       0.92      0.92      0.92       500\n",
            "\n",
            "0  Training Loss:  tensor(0.1249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "1  Training Loss:  tensor(0.0903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "2  Training Loss:  tensor(0.0240, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "3  Training Loss:  tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "4  Training Loss:  tensor(0.1687, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "5  Training Loss:  tensor(0.0217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "6  Training Loss:  tensor(0.0846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "7  Training Loss:  tensor(0.3370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "8  Training Loss:  tensor(0.0614, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "9  Training Loss:  tensor(0.4100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "10  Training Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "11  Training Loss:  tensor(0.4546, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "12  Training Loss:  tensor(0.0214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "13  Training Loss:  tensor(0.6819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "14  Training Loss:  tensor(0.7175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "15  Training Loss:  tensor(0.1526, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "16  Training Loss:  tensor(0.0354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "17  Training Loss:  tensor(0.5009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "18  Training Loss:  tensor(0.0378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "19  Training Loss:  tensor(0.4007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "20  Training Loss:  tensor(0.2021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "21  Training Loss:  tensor(0.0243, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "22  Training Loss:  tensor(0.0707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "23  Training Loss:  tensor(0.2141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "24  Training Loss:  tensor(0.3704, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "25  Training Loss:  tensor(0.1473, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "26  Training Loss:  tensor(0.1664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "27  Training Loss:  tensor(0.1432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "28  Training Loss:  tensor(0.0962, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "29  Training Loss:  tensor(0.0152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "30  Training Loss:  tensor(0.1874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "31  Training Loss:  tensor(0.0378, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "32  Training Loss:  tensor(0.0843, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "33  Training Loss:  tensor(0.4340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "34  Training Loss:  tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "35  Training Loss:  tensor(0.1115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "36  Training Loss:  tensor(0.2238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "37  Training Loss:  tensor(0.0532, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "38  Training Loss:  tensor(0.1220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "39  Training Loss:  tensor(0.1453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "40  Training Loss:  tensor(0.0835, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "41  Training Loss:  tensor(0.7544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "42  Training Loss:  tensor(0.1576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "43  Training Loss:  tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "44  Training Loss:  tensor(0.0149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "45  Training Loss:  tensor(0.1831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "46  Training Loss:  tensor(0.0208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "47  Training Loss:  tensor(0.0114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "48  Training Loss:  tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "49  Training Loss:  tensor(0.4780, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "50  Training Loss:  tensor(0.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "51  Training Loss:  tensor(0.0289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "52  Training Loss:  tensor(0.1049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "53  Training Loss:  tensor(0.4346, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "54  Training Loss:  tensor(0.0361, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "55  Training Loss:  tensor(0.0119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "56  Training Loss:  tensor(0.1971, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "57  Training Loss:  tensor(0.0192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "58  Training Loss:  tensor(0.6133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "59  Training Loss:  tensor(0.0588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "60  Training Loss:  tensor(0.1192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "61  Training Loss:  tensor(0.0148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "62  Training Loss:  tensor(0.2830, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "63  Training Loss:  tensor(0.3755, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "64  Training Loss:  tensor(0.1431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "65  Training Loss:  tensor(0.0404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "66  Training Loss:  tensor(0.3252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "67  Training Loss:  tensor(0.0373, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "68  Training Loss:  tensor(0.1590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "69  Training Loss:  tensor(0.1939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "70  Training Loss:  tensor(0.0626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "71  Training Loss:  tensor(0.0696, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "72  Training Loss:  tensor(0.0307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "73  Training Loss:  tensor(0.0466, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "74  Training Loss:  tensor(0.0635, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "75  Training Loss:  tensor(0.2203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "76  Training Loss:  tensor(0.0451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "77  Training Loss:  tensor(0.1005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "78  Training Loss:  tensor(0.0566, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "79  Training Loss:  tensor(0.0272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "80  Training Loss:  tensor(0.5519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "81  Training Loss:  tensor(0.0333, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "82  Training Loss:  tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "83  Training Loss:  tensor(0.3460, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "84  Training Loss:  tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "85  Training Loss:  tensor(0.1516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "86  Training Loss:  tensor(0.0833, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "87  Training Loss:  tensor(0.1760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "88  Training Loss:  tensor(0.2476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "89  Training Loss:  tensor(0.0902, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "90  Training Loss:  tensor(0.7219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "91  Training Loss:  tensor(0.0281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "92  Training Loss:  tensor(0.4370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "93  Training Loss:  tensor(0.0403, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "94  Training Loss:  tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "95  Training Loss:  tensor(0.5475, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "96  Training Loss:  tensor(0.3496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "97  Training Loss:  tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "98  Training Loss:  tensor(0.0572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "99  Training Loss:  tensor(0.0388, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100  Training Loss:  tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "101  Training Loss:  tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "102  Training Loss:  tensor(0.0739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "103  Training Loss:  tensor(0.2014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "104  Training Loss:  tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "105  Training Loss:  tensor(0.0619, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "106  Training Loss:  tensor(0.1673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "107  Training Loss:  tensor(0.2513, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "108  Training Loss:  tensor(0.0667, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "109  Training Loss:  tensor(0.3700, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "110  Training Loss:  tensor(0.0203, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "111  Training Loss:  tensor(0.3794, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "112  Training Loss:  tensor(0.4270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "113  Training Loss:  tensor(0.0449, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "114  Training Loss:  tensor(0.1318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "115  Training Loss:  tensor(0.2055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "116  Training Loss:  tensor(0.1152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "117  Training Loss:  tensor(0.0501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "118  Training Loss:  tensor(0.3524, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "119  Training Loss:  tensor(0.1800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "120  Training Loss:  tensor(0.2854, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "121  Training Loss:  tensor(0.1681, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "122  Training Loss:  tensor(0.0135, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "123  Training Loss:  tensor(0.2406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "124  Training Loss:  tensor(0.0450, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "125  Training Loss:  tensor(0.0916, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "126  Training Loss:  tensor(0.0171, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "127  Training Loss:  tensor(0.1226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "128  Training Loss:  tensor(0.0535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "129  Training Loss:  tensor(0.0202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "130  Training Loss:  tensor(0.3867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "131  Training Loss:  tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "132  Training Loss:  tensor(0.3278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "133  Training Loss:  tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "134  Training Loss:  tensor(0.0530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "135  Training Loss:  tensor(0.0938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "136  Training Loss:  tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "137  Training Loss:  tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "138  Training Loss:  tensor(0.0729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "139  Training Loss:  tensor(0.0096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "140  Training Loss:  tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "141  Training Loss:  tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "142  Training Loss:  tensor(0.3096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "143  Training Loss:  tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "144  Training Loss:  tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "145  Training Loss:  tensor(0.6840, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "146  Training Loss:  tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "147  Training Loss:  tensor(0.1258, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "148  Training Loss:  tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "149  Training Loss:  tensor(0.0320, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "150  Training Loss:  tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "151  Training Loss:  tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "152  Training Loss:  tensor(0.2306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "153  Training Loss:  tensor(0.5285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "154  Training Loss:  tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "155  Training Loss:  tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "156  Training Loss:  tensor(0.6545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "157  Training Loss:  tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "158  Training Loss:  tensor(0.0677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "159  Training Loss:  tensor(0.1585, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "160  Training Loss:  tensor(0.0217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "161  Training Loss:  tensor(1.0129, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "162  Training Loss:  tensor(0.1368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "163  Training Loss:  tensor(0.1582, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "164  Training Loss:  tensor(0.3371, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "165  Training Loss:  tensor(0.1064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "166  Training Loss:  tensor(0.2067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "167  Training Loss:  tensor(0.4846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "168  Training Loss:  tensor(0.0590, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "169  Training Loss:  tensor(0.1200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "170  Training Loss:  tensor(0.1531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "171  Training Loss:  tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "172  Training Loss:  tensor(0.0422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "173  Training Loss:  tensor(0.0643, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "174  Training Loss:  tensor(0.3112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "175  Training Loss:  tensor(0.1752, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "176  Training Loss:  tensor(0.3347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "177  Training Loss:  tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "178  Training Loss:  tensor(0.5757, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "179  Training Loss:  tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "180  Training Loss:  tensor(0.1387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "181  Training Loss:  tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "182  Training Loss:  tensor(0.2743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "183  Training Loss:  tensor(0.1006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "184  Training Loss:  tensor(0.1247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "185  Training Loss:  tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "186  Training Loss:  tensor(0.7612, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "187  Training Loss:  tensor(0.1530, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "188  Training Loss:  tensor(0.1406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "189  Training Loss:  tensor(0.1219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "190  Training Loss:  tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "191  Training Loss:  tensor(0.0338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "192  Training Loss:  tensor(0.0442, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "193  Training Loss:  tensor(0.2459, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "194  Training Loss:  tensor(0.0236, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "195  Training Loss:  tensor(0.1302, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "196  Training Loss:  tensor(0.0593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "197  Training Loss:  tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "198  Training Loss:  tensor(0.0718, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "199  Training Loss:  tensor(0.2751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "200  Training Loss:  tensor(0.0350, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "201  Training Loss:  tensor(0.2756, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "202  Training Loss:  tensor(0.0182, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "203  Training Loss:  tensor(0.4620, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "204  Training Loss:  tensor(0.2802, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "205  Training Loss:  tensor(0.8950, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "206  Training Loss:  tensor(0.0494, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "207  Training Loss:  tensor(0.1079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "208  Training Loss:  tensor(0.1777, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "209  Training Loss:  tensor(0.0114, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "210  Training Loss:  tensor(0.0820, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "211  Training Loss:  tensor(0.1734, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "212  Training Loss:  tensor(1.1273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "213  Training Loss:  tensor(0.0141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "214  Training Loss:  tensor(0.0420, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "215  Training Loss:  tensor(0.0192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "216  Training Loss:  tensor(0.0471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "217  Training Loss:  tensor(0.1877, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "218  Training Loss:  tensor(0.1173, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "219  Training Loss:  tensor(0.0772, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "220  Training Loss:  tensor(0.0472, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "221  Training Loss:  tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "222  Training Loss:  tensor(0.2048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "223  Training Loss:  tensor(0.0690, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "224  Training Loss:  tensor(0.2451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "225  Training Loss:  tensor(0.5253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "226  Training Loss:  tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "227  Training Loss:  tensor(0.1693, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "228  Training Loss:  tensor(0.1053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "229  Training Loss:  tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "230  Training Loss:  tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "231  Training Loss:  tensor(0.0252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "232  Training Loss:  tensor(0.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "233  Training Loss:  tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "234  Training Loss:  tensor(0.0161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "235  Training Loss:  tensor(0.3115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "236  Training Loss:  tensor(0.1476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "237  Training Loss:  tensor(0.3272, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "238  Training Loss:  tensor(0.4871, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "239  Training Loss:  tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "240  Training Loss:  tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "241  Training Loss:  tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "242  Training Loss:  tensor(0.2817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "243  Training Loss:  tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "244  Training Loss:  tensor(0.0121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "245  Training Loss:  tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "246  Training Loss:  tensor(0.4979, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "247  Training Loss:  tensor(1.3869, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "248  Training Loss:  tensor(0.1137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "249  Training Loss:  tensor(0.1514, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "250  Training Loss:  tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "251  Training Loss:  tensor(0.1119, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "252  Training Loss:  tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "253  Training Loss:  tensor(0.2846, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "254  Training Loss:  tensor(0.1887, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "255  Training Loss:  tensor(0.1325, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "256  Training Loss:  tensor(0.2751, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "257  Training Loss:  tensor(0.0543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "258  Training Loss:  tensor(0.2138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "259  Training Loss:  tensor(0.3519, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "260  Training Loss:  tensor(0.0520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "261  Training Loss:  tensor(0.0238, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "262  Training Loss:  tensor(0.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "263  Training Loss:  tensor(0.1106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "264  Training Loss:  tensor(0.0870, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "265  Training Loss:  tensor(0.0331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "266  Training Loss:  tensor(0.5976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "267  Training Loss:  tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "268  Training Loss:  tensor(0.3488, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "269  Training Loss:  tensor(0.6065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "270  Training Loss:  tensor(0.2157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "271  Training Loss:  tensor(0.1698, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "272  Training Loss:  tensor(0.0539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "273  Training Loss:  tensor(0.2006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "274  Training Loss:  tensor(0.1254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "275  Training Loss:  tensor(0.1565, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "276  Training Loss:  tensor(0.0357, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "277  Training Loss:  tensor(0.2707, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "278  Training Loss:  tensor(0.3344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "279  Training Loss:  tensor(0.1124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "280  Training Loss:  tensor(0.2175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "281  Training Loss:  tensor(0.2398, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "282  Training Loss:  tensor(0.3227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "283  Training Loss:  tensor(0.0414, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "284  Training Loss:  tensor(0.0457, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "285  Training Loss:  tensor(0.0562, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "286  Training Loss:  tensor(0.1092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "287  Training Loss:  tensor(0.1194, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "288  Training Loss:  tensor(0.2188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "289  Training Loss:  tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "290  Training Loss:  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "291  Training Loss:  tensor(0.1922, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "292  Training Loss:  tensor(0.2065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "293  Training Loss:  tensor(0.1273, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "294  Training Loss:  tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "295  Training Loss:  tensor(0.2028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "296  Training Loss:  tensor(0.1804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "297  Training Loss:  tensor(0.2223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "298  Training Loss:  tensor(0.7052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "299  Training Loss:  tensor(0.0159, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "300  Training Loss:  tensor(0.0213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "301  Training Loss:  tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "302  Training Loss:  tensor(0.0446, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "303  Training Loss:  tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "304  Training Loss:  tensor(0.0654, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "305  Training Loss:  tensor(0.0102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "306  Training Loss:  tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "307  Training Loss:  tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "308  Training Loss:  tensor(0.0311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "309  Training Loss:  tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "310  Training Loss:  tensor(0.1092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "311  Training Loss:  tensor(0.0101, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "312  Training Loss:  tensor(0.0126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "313  Training Loss:  tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "314  Training Loss:  tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "315  Training Loss:  tensor(0.0691, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "316  Training Loss:  tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "317  Training Loss:  tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "318  Training Loss:  tensor(0.0103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "319  Training Loss:  tensor(0.2339, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "320  Training Loss:  tensor(0.2334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "321  Training Loss:  tensor(0.0942, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "322  Training Loss:  tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "323  Training Loss:  tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "324  Training Loss:  tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "325  Training Loss:  tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "326  Training Loss:  tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "327  Training Loss:  tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "328  Training Loss:  tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "329  Training Loss:  tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "330  Training Loss:  tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "331  Training Loss:  tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "332  Training Loss:  tensor(0.0630, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "333  Training Loss:  tensor(0.0474, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "334  Training Loss:  tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "335  Training Loss:  tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "336  Training Loss:  tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "337  Training Loss:  tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "338  Training Loss:  tensor(0.1292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "339  Training Loss:  tensor(0.7267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "340  Training Loss:  tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "341  Training Loss:  tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "342  Training Loss:  tensor(0.0572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "343  Training Loss:  tensor(0.2052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "344  Training Loss:  tensor(0.2409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "345  Training Loss:  tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "346  Training Loss:  tensor(1.0683, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "347  Training Loss:  tensor(0.0201, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "348  Training Loss:  tensor(0.4623, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "349  Training Loss:  tensor(0.2867, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "350  Training Loss:  tensor(0.0939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "351  Training Loss:  tensor(0.5370, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "352  Training Loss:  tensor(0.0399, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "353  Training Loss:  tensor(0.0529, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "354  Training Loss:  tensor(0.0284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "355  Training Loss:  tensor(0.1677, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "356  Training Loss:  tensor(0.0765, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "357  Training Loss:  tensor(0.0295, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "358  Training Loss:  tensor(0.1018, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "359  Training Loss:  tensor(0.1814, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "360  Training Loss:  tensor(0.0709, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "361  Training Loss:  tensor(0.5385, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "362  Training Loss:  tensor(0.0328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "363  Training Loss:  tensor(0.0293, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "364  Training Loss:  tensor(0.1089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "365  Training Loss:  tensor(0.2588, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "366  Training Loss:  tensor(0.1496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "367  Training Loss:  tensor(0.0785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "368  Training Loss:  tensor(0.1894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "369  Training Loss:  tensor(0.0535, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "370  Training Loss:  tensor(0.0462, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "371  Training Loss:  tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "372  Training Loss:  tensor(0.0368, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "373  Training Loss:  tensor(0.0387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "374  Training Loss:  tensor(0.6180, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "375  Training Loss:  tensor(0.1719, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "376  Training Loss:  tensor(0.0531, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "377  Training Loss:  tensor(0.2747, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "378  Training Loss:  tensor(0.4816, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "379  Training Loss:  tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "380  Training Loss:  tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "381  Training Loss:  tensor(0.8202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "382  Training Loss:  tensor(0.0629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "383  Training Loss:  tensor(0.0118, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "384  Training Loss:  tensor(0.1251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "385  Training Loss:  tensor(0.0291, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "386  Training Loss:  tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "387  Training Loss:  tensor(0.2313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "388  Training Loss:  tensor(0.7760, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "389  Training Loss:  tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "390  Training Loss:  tensor(0.0555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "391  Training Loss:  tensor(0.0344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "392  Training Loss:  tensor(0.3545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "393  Training Loss:  tensor(0.0430, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "394  Training Loss:  tensor(0.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "395  Training Loss:  tensor(0.0313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "396  Training Loss:  tensor(0.5906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "397  Training Loss:  tensor(0.4441, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "398  Training Loss:  tensor(0.0490, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "399  Training Loss:  tensor(0.2354, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "400  Training Loss:  tensor(0.1742, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "401  Training Loss:  tensor(0.5409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "402  Training Loss:  tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "403  Training Loss:  tensor(0.1544, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "404  Training Loss:  tensor(0.0739, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "405  Training Loss:  tensor(0.0938, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "406  Training Loss:  tensor(0.1382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "407  Training Loss:  tensor(0.0252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "408  Training Loss:  tensor(0.0819, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "409  Training Loss:  tensor(0.0610, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "410  Training Loss:  tensor(0.0392, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "411  Training Loss:  tensor(0.3256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "412  Training Loss:  tensor(0.0439, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "413  Training Loss:  tensor(0.6193, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "414  Training Loss:  tensor(0.0267, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "415  Training Loss:  tensor(0.0191, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "416  Training Loss:  tensor(0.1790, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "417  Training Loss:  tensor(0.1503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "418  Training Loss:  tensor(0.2409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "419  Training Loss:  tensor(0.3655, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "420  Training Loss:  tensor(0.5785, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "421  Training Loss:  tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "422  Training Loss:  tensor(0.1393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "423  Training Loss:  tensor(0.0547, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "424  Training Loss:  tensor(0.4409, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "425  Training Loss:  tensor(0.0206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "426  Training Loss:  tensor(0.0270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "427  Training Loss:  tensor(0.5233, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "428  Training Loss:  tensor(0.0249, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "429  Training Loss:  tensor(0.0377, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "430  Training Loss:  tensor(0.0874, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "431  Training Loss:  tensor(0.0678, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "432  Training Loss:  tensor(0.0611, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "433  Training Loss:  tensor(0.0543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "434  Training Loss:  tensor(0.0539, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "435  Training Loss:  tensor(0.7463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "436  Training Loss:  tensor(0.0141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "437  Training Loss:  tensor(0.0263, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.60      0.22      0.32        27\n",
            "           1       0.95      0.95      0.95       381\n",
            "           2       0.83      0.96      0.89        92\n",
            "\n",
            "    accuracy                           0.91       500\n",
            "   macro avg       0.79      0.71      0.72       500\n",
            "weighted avg       0.91      0.91      0.90       500\n",
            "\n",
            "0  Training Loss:  tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "1  Training Loss:  tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "2  Training Loss:  tensor(0.0280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "3  Training Loss:  tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "4  Training Loss:  tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "5  Training Loss:  tensor(0.0393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "6  Training Loss:  tensor(0.0192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "7  Training Loss:  tensor(0.0380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "8  Training Loss:  tensor(0.0079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "9  Training Loss:  tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "10  Training Loss:  tensor(0.0145, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "11  Training Loss:  tensor(0.0140, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "12  Training Loss:  tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "13  Training Loss:  tensor(0.1274, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "14  Training Loss:  tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "15  Training Loss:  tensor(0.0684, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "16  Training Loss:  tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "17  Training Loss:  tensor(0.0746, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "18  Training Loss:  tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "19  Training Loss:  tensor(0.0319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "20  Training Loss:  tensor(0.1142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "21  Training Loss:  tensor(0.2715, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "22  Training Loss:  tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "23  Training Loss:  tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "24  Training Loss:  tensor(0.0095, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "25  Training Loss:  tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "26  Training Loss:  tensor(0.4260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "27  Training Loss:  tensor(0.0810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "28  Training Loss:  tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "29  Training Loss:  tensor(0.1172, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "30  Training Loss:  tensor(0.1629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "31  Training Loss:  tensor(0.1123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "32  Training Loss:  tensor(0.0332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "33  Training Loss:  tensor(0.0688, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "34  Training Loss:  tensor(0.0689, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "35  Training Loss:  tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "36  Training Loss:  tensor(0.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "37  Training Loss:  tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "38  Training Loss:  tensor(0.2369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "39  Training Loss:  tensor(0.0254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "40  Training Loss:  tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "41  Training Loss:  tensor(0.0829, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "42  Training Loss:  tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "43  Training Loss:  tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "44  Training Loss:  tensor(0.0629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "45  Training Loss:  tensor(0.3491, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "46  Training Loss:  tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "47  Training Loss:  tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "48  Training Loss:  tensor(0.7890, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "49  Training Loss:  tensor(0.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "50  Training Loss:  tensor(0.0875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "51  Training Loss:  tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "52  Training Loss:  tensor(0.0725, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "53  Training Loss:  tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "54  Training Loss:  tensor(0.0918, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "55  Training Loss:  tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "56  Training Loss:  tensor(0.1344, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "57  Training Loss:  tensor(0.0284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "58  Training Loss:  tensor(0.0154, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "59  Training Loss:  tensor(0.0220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "60  Training Loss:  tensor(0.3330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "61  Training Loss:  tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "62  Training Loss:  tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "63  Training Loss:  tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "64  Training Loss:  tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "65  Training Loss:  tensor(0.0340, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "66  Training Loss:  tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "67  Training Loss:  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "68  Training Loss:  tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "69  Training Loss:  tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "70  Training Loss:  tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "71  Training Loss:  tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "72  Training Loss:  tensor(0.0929, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "73  Training Loss:  tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "74  Training Loss:  tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "75  Training Loss:  tensor(0.4161, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "76  Training Loss:  tensor(0.2160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "77  Training Loss:  tensor(0.3144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "78  Training Loss:  tensor(0.0268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "79  Training Loss:  tensor(0.0865, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "80  Training Loss:  tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "81  Training Loss:  tensor(0.0334, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "82  Training Loss:  tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "83  Training Loss:  tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "84  Training Loss:  tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "85  Training Loss:  tensor(0.0753, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "86  Training Loss:  tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "87  Training Loss:  tensor(0.0365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "88  Training Loss:  tensor(0.0967, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "89  Training Loss:  tensor(0.0083, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "90  Training Loss:  tensor(0.0823, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "91  Training Loss:  tensor(0.1143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "92  Training Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "93  Training Loss:  tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "94  Training Loss:  tensor(0.0153, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "95  Training Loss:  tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "96  Training Loss:  tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "97  Training Loss:  tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "98  Training Loss:  tensor(0.0220, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "99  Training Loss:  tensor(0.1010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100  Training Loss:  tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "101  Training Loss:  tensor(0.6559, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "102  Training Loss:  tensor(0.0239, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "103  Training Loss:  tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "104  Training Loss:  tensor(0.0496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "105  Training Loss:  tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "106  Training Loss:  tensor(0.0126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "107  Training Loss:  tensor(0.0421, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "108  Training Loss:  tensor(0.0800, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "109  Training Loss:  tensor(0.1284, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "110  Training Loss:  tensor(0.0206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "111  Training Loss:  tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "112  Training Loss:  tensor(0.2601, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "113  Training Loss:  tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "114  Training Loss:  tensor(0.0115, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "115  Training Loss:  tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "116  Training Loss:  tensor(0.0876, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "117  Training Loss:  tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "118  Training Loss:  tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "119  Training Loss:  tensor(0.0824, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "120  Training Loss:  tensor(0.2000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "121  Training Loss:  tensor(0.2542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "122  Training Loss:  tensor(0.0318, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "123  Training Loss:  tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "124  Training Loss:  tensor(0.2382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "125  Training Loss:  tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "126  Training Loss:  tensor(0.3471, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "127  Training Loss:  tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "128  Training Loss:  tensor(0.0432, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "129  Training Loss:  tensor(0.2134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "130  Training Loss:  tensor(0.1105, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "131  Training Loss:  tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "132  Training Loss:  tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "133  Training Loss:  tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "134  Training Loss:  tensor(0.0970, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "135  Training Loss:  tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "136  Training Loss:  tensor(0.0146, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "137  Training Loss:  tensor(0.3856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "138  Training Loss:  tensor(0.0892, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "139  Training Loss:  tensor(0.1463, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "140  Training Loss:  tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "141  Training Loss:  tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "142  Training Loss:  tensor(0.0096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "143  Training Loss:  tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "144  Training Loss:  tensor(0.1525, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "145  Training Loss:  tensor(0.1061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "146  Training Loss:  tensor(0.1960, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "147  Training Loss:  tensor(0.0209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "148  Training Loss:  tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "149  Training Loss:  tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "150  Training Loss:  tensor(0.0393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "151  Training Loss:  tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "152  Training Loss:  tensor(0.3673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "153  Training Loss:  tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "154  Training Loss:  tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "155  Training Loss:  tensor(0.2045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "156  Training Loss:  tensor(0.0347, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "157  Training Loss:  tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "158  Training Loss:  tensor(0.2640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "159  Training Loss:  tensor(0.0705, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "160  Training Loss:  tensor(0.4055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "161  Training Loss:  tensor(0.1120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "162  Training Loss:  tensor(0.1476, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "163  Training Loss:  tensor(0.0150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "164  Training Loss:  tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "165  Training Loss:  tensor(0.1079, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "166  Training Loss:  tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "167  Training Loss:  tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "168  Training Loss:  tensor(0.1817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "169  Training Loss:  tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "170  Training Loss:  tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "171  Training Loss:  tensor(0.0575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "172  Training Loss:  tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "173  Training Loss:  tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "174  Training Loss:  tensor(0.4500, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "175  Training Loss:  tensor(0.0496, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "176  Training Loss:  tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "177  Training Loss:  tensor(0.1247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "178  Training Loss:  tensor(0.0376, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "179  Training Loss:  tensor(0.0131, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "180  Training Loss:  tensor(0.3477, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "181  Training Loss:  tensor(0.1309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "182  Training Loss:  tensor(0.0177, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "183  Training Loss:  tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "184  Training Loss:  tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "185  Training Loss:  tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "186  Training Loss:  tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "187  Training Loss:  tensor(0.0061, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "188  Training Loss:  tensor(0.0213, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "189  Training Loss:  tensor(0.0672, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "190  Training Loss:  tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "191  Training Loss:  tensor(0.0503, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "192  Training Loss:  tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "193  Training Loss:  tensor(0.2767, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "194  Training Loss:  tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "195  Training Loss:  tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "196  Training Loss:  tensor(0.2939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "197  Training Loss:  tensor(0.2242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "198  Training Loss:  tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "199  Training Loss:  tensor(0.0973, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "200  Training Loss:  tensor(0.0218, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "201  Training Loss:  tensor(0.1252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "202  Training Loss:  tensor(0.0410, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "203  Training Loss:  tensor(0.0262, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "204  Training Loss:  tensor(0.0219, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "205  Training Loss:  tensor(0.1086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "206  Training Loss:  tensor(0.1250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "207  Training Loss:  tensor(0.0987, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "208  Training Loss:  tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "209  Training Loss:  tensor(0.0351, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "210  Training Loss:  tensor(0.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "211  Training Loss:  tensor(0.0536, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "212  Training Loss:  tensor(0.0178, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "213  Training Loss:  tensor(0.0400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "214  Training Loss:  tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "215  Training Loss:  tensor(0.0091, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "216  Training Loss:  tensor(0.5729, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "217  Training Loss:  tensor(0.1652, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "218  Training Loss:  tensor(0.1268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "219  Training Loss:  tensor(0.0076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "220  Training Loss:  tensor(0.6728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "221  Training Loss:  tensor(0.5345, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "222  Training Loss:  tensor(0.0156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "223  Training Loss:  tensor(0.0609, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "224  Training Loss:  tensor(0.0375, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "225  Training Loss:  tensor(0.0621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "226  Training Loss:  tensor(0.0961, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "227  Training Loss:  tensor(0.9404, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "228  Training Loss:  tensor(0.0200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "229  Training Loss:  tensor(0.0381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "230  Training Loss:  tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "231  Training Loss:  tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "232  Training Loss:  tensor(0.5580, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "233  Training Loss:  tensor(0.0299, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "234  Training Loss:  tensor(0.0260, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "235  Training Loss:  tensor(0.1389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "236  Training Loss:  tensor(1.0935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "237  Training Loss:  tensor(0.2891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "238  Training Loss:  tensor(0.0230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "239  Training Loss:  tensor(0.0217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "240  Training Loss:  tensor(0.1666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "241  Training Loss:  tensor(0.4341, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "242  Training Loss:  tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "243  Training Loss:  tensor(0.0848, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "244  Training Loss:  tensor(0.0176, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "245  Training Loss:  tensor(0.0453, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "246  Training Loss:  tensor(0.1906, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "247  Training Loss:  tensor(0.0230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "248  Training Loss:  tensor(0.0168, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "249  Training Loss:  tensor(0.0142, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "250  Training Loss:  tensor(0.1651, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "251  Training Loss:  tensor(0.2996, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "252  Training Loss:  tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "253  Training Loss:  tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "254  Training Loss:  tensor(0.0255, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "255  Training Loss:  tensor(0.0125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "256  Training Loss:  tensor(0.0103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "257  Training Loss:  tensor(0.1452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "258  Training Loss:  tensor(0.0059, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "259  Training Loss:  tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "260  Training Loss:  tensor(0.0242, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "261  Training Loss:  tensor(0.0791, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "262  Training Loss:  tensor(0.0400, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "263  Training Loss:  tensor(0.0080, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "264  Training Loss:  tensor(0.0977, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "265  Training Loss:  tensor(0.5523, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "266  Training Loss:  tensor(0.0206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "267  Training Loss:  tensor(0.1331, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "268  Training Loss:  tensor(0.0078, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "269  Training Loss:  tensor(0.1029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "270  Training Loss:  tensor(0.1520, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "271  Training Loss:  tensor(0.0294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "272  Training Loss:  tensor(0.0452, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "273  Training Loss:  tensor(0.0124, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "274  Training Loss:  tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "275  Training Loss:  tensor(0.7338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "276  Training Loss:  tensor(0.1856, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "277  Training Loss:  tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "278  Training Loss:  tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "279  Training Loss:  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "280  Training Loss:  tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "281  Training Loss:  tensor(0.2510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "282  Training Loss:  tensor(0.3270, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "283  Training Loss:  tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "284  Training Loss:  tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "285  Training Loss:  tensor(0.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "286  Training Loss:  tensor(0.0708, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "287  Training Loss:  tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "288  Training Loss:  tensor(0.0324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "289  Training Loss:  tensor(0.1183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "290  Training Loss:  tensor(0.0207, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "291  Training Loss:  tensor(0.1307, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "292  Training Loss:  tensor(0.0216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "293  Training Loss:  tensor(0.1332, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "294  Training Loss:  tensor(0.0183, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "295  Training Loss:  tensor(0.1188, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "296  Training Loss:  tensor(0.0245, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "297  Training Loss:  tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "298  Training Loss:  tensor(0.0422, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "299  Training Loss:  tensor(0.0112, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "300  Training Loss:  tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "301  Training Loss:  tensor(0.0618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "302  Training Loss:  tensor(0.0510, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "303  Training Loss:  tensor(0.1716, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "304  Training Loss:  tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "305  Training Loss:  tensor(0.0077, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "306  Training Loss:  tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "307  Training Loss:  tensor(0.6204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "308  Training Loss:  tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "309  Training Loss:  tensor(0.0075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "310  Training Loss:  tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "311  Training Loss:  tensor(0.1438, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "312  Training Loss:  tensor(0.0875, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "313  Training Loss:  tensor(0.0855, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "314  Training Loss:  tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "315  Training Loss:  tensor(0.1593, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "316  Training Loss:  tensor(0.0204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "317  Training Loss:  tensor(0.0737, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "318  Training Loss:  tensor(0.0338, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "319  Training Loss:  tensor(0.1250, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "320  Training Loss:  tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "321  Training Loss:  tensor(0.3324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "322  Training Loss:  tensor(0.0294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "323  Training Loss:  tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "324  Training Loss:  tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "325  Training Loss:  tensor(0.0319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "326  Training Loss:  tensor(0.0895, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "327  Training Loss:  tensor(0.0676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "328  Training Loss:  tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "329  Training Loss:  tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "330  Training Loss:  tensor(0.0664, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "331  Training Loss:  tensor(0.6230, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "332  Training Loss:  tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "333  Training Loss:  tensor(0.3988, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "334  Training Loss:  tensor(0.0208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "335  Training Loss:  tensor(0.1144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "336  Training Loss:  tensor(0.0676, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "337  Training Loss:  tensor(0.1133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "338  Training Loss:  tensor(0.0223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "339  Training Loss:  tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "340  Training Loss:  tensor(0.0397, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "341  Training Loss:  tensor(0.2955, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "342  Training Loss:  tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "343  Training Loss:  tensor(0.1927, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "344  Training Loss:  tensor(0.3292, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "345  Training Loss:  tensor(0.0214, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "346  Training Loss:  tensor(0.0470, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "347  Training Loss:  tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "348  Training Loss:  tensor(0.0151, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "349  Training Loss:  tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "350  Training Loss:  tensor(0.0891, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "351  Training Loss:  tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "352  Training Loss:  tensor(0.0640, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "353  Training Loss:  tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "354  Training Loss:  tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "355  Training Loss:  tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "356  Training Loss:  tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "357  Training Loss:  tensor(0.2121, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "358  Training Loss:  tensor(0.2533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "359  Training Loss:  tensor(0.0323, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "360  Training Loss:  tensor(0.1387, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "361  Training Loss:  tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "362  Training Loss:  tensor(0.1903, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "363  Training Loss:  tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "364  Training Loss:  tensor(0.1030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "365  Training Loss:  tensor(0.0405, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "366  Training Loss:  tensor(0.1117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "367  Training Loss:  tensor(0.0603, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "368  Training Loss:  tensor(0.4103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "369  Training Loss:  tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "370  Training Loss:  tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "371  Training Loss:  tensor(0.0957, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "372  Training Loss:  tensor(0.1849, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "373  Training Loss:  tensor(0.0991, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "374  Training Loss:  tensor(0.0311, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "375  Training Loss:  tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "376  Training Loss:  tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "377  Training Loss:  tensor(0.4076, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "378  Training Loss:  tensor(0.0283, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "379  Training Loss:  tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "380  Training Loss:  tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "381  Training Loss:  tensor(0.0285, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "382  Training Loss:  tensor(0.2395, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "383  Training Loss:  tensor(0.0545, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "384  Training Loss:  tensor(0.1542, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "385  Training Loss:  tensor(0.1184, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "386  Training Loss:  tensor(0.0380, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "387  Training Loss:  tensor(0.1065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "388  Training Loss:  tensor(0.0649, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "389  Training Loss:  tensor(0.0328, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "390  Training Loss:  tensor(0.5206, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "391  Training Loss:  tensor(0.0572, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "392  Training Loss:  tensor(0.0335, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "393  Training Loss:  tensor(0.0554, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "394  Training Loss:  tensor(0.4130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "395  Training Loss:  tensor(0.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "396  Training Loss:  tensor(0.2241, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "397  Training Loss:  tensor(0.0666, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "398  Training Loss:  tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "399  Training Loss:  tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "400  Training Loss:  tensor(0.1316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "401  Training Loss:  tensor(0.0084, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "402  Training Loss:  tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "403  Training Loss:  tensor(0.0198, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "404  Training Loss:  tensor(0.0174, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "405  Training Loss:  tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "406  Training Loss:  tensor(0.0103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "407  Training Loss:  tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "408  Training Loss:  tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "409  Training Loss:  tensor(0.1406, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "410  Training Loss:  tensor(0.1810, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "411  Training Loss:  tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "412  Training Loss:  tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "413  Training Loss:  tensor(0.0192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "414  Training Loss:  tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "415  Training Loss:  tensor(0.0289, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "416  Training Loss:  tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "417  Training Loss:  tensor(0.0416, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "418  Training Loss:  tensor(0.0567, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "419  Training Loss:  tensor(0.2330, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "420  Training Loss:  tensor(0.1831, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "421  Training Loss:  tensor(0.0618, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "422  Training Loss:  tensor(0.0136, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "423  Training Loss:  tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "424  Training Loss:  tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "425  Training Loss:  tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "426  Training Loss:  tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "427  Training Loss:  tensor(0.1534, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "428  Training Loss:  tensor(0.1021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "429  Training Loss:  tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "430  Training Loss:  tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "431  Training Loss:  tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "432  Training Loss:  tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "433  Training Loss:  tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "434  Training Loss:  tensor(0.1517, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "435  Training Loss:  tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "436  Training Loss:  tensor(0.8913, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "437  Training Loss:  tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.45      0.37      0.41        27\n",
            "           1       0.95      0.95      0.95       381\n",
            "           2       0.86      0.92      0.89        92\n",
            "\n",
            "    accuracy                           0.91       500\n",
            "   macro avg       0.76      0.75      0.75       500\n",
            "weighted avg       0.91      0.91      0.91       500\n",
            "\n",
            "0  Training Loss:  tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "1  Training Loss:  tensor(0.0102, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "2  Training Loss:  tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "3  Training Loss:  tensor(0.0123, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "4  Training Loss:  tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "5  Training Loss:  tensor(0.0279, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "6  Training Loss:  tensor(0.0144, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "7  Training Loss:  tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "8  Training Loss:  tensor(0.0336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "9  Training Loss:  tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "10  Training Loss:  tensor(0.0088, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "11  Training Loss:  tensor(0.0187, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "12  Training Loss:  tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "13  Training Loss:  tensor(0.0786, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "14  Training Loss:  tensor(0.0382, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "15  Training Loss:  tensor(0.1141, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "16  Training Loss:  tensor(0.0081, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "17  Training Loss:  tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "18  Training Loss:  tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "19  Training Loss:  tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "20  Training Loss:  tensor(0.0026, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "21  Training Loss:  tensor(0.0329, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "22  Training Loss:  tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "23  Training Loss:  tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "24  Training Loss:  tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "25  Training Loss:  tensor(0.0247, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "26  Training Loss:  tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "27  Training Loss:  tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "28  Training Loss:  tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "29  Training Loss:  tensor(0.0389, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "30  Training Loss:  tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "31  Training Loss:  tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "32  Training Loss:  tensor(0.0694, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "33  Training Loss:  tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "34  Training Loss:  tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "35  Training Loss:  tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "36  Training Loss:  tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "37  Training Loss:  tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "38  Training Loss:  tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "39  Training Loss:  tensor(0.0044, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "40  Training Loss:  tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "41  Training Loss:  tensor(0.2776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "42  Training Loss:  tensor(0.2527, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "43  Training Loss:  tensor(0.8103, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "44  Training Loss:  tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "45  Training Loss:  tensor(0.6087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "46  Training Loss:  tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "47  Training Loss:  tensor(0.1917, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "48  Training Loss:  tensor(0.1152, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "49  Training Loss:  tensor(0.0126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "50  Training Loss:  tensor(0.0160, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "51  Training Loss:  tensor(0.0157, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "52  Training Loss:  tensor(0.0407, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "53  Training Loss:  tensor(0.1235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "54  Training Loss:  tensor(0.0714, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "55  Training Loss:  tensor(0.0695, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "56  Training Loss:  tensor(0.1099, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "57  Training Loss:  tensor(0.0217, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "58  Training Loss:  tensor(0.0133, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "59  Training Loss:  tensor(0.0223, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "60  Training Loss:  tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "61  Training Loss:  tensor(0.0106, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "62  Training Loss:  tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "63  Training Loss:  tensor(0.0175, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "64  Training Loss:  tensor(0.0256, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "65  Training Loss:  tensor(0.1817, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "66  Training Loss:  tensor(0.0227, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "67  Training Loss:  tensor(0.0673, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "68  Training Loss:  tensor(0.0424, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "69  Training Loss:  tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "70  Training Loss:  tensor(0.0506, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "71  Training Loss:  tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "72  Training Loss:  tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "73  Training Loss:  tensor(0.0555, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "74  Training Loss:  tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "75  Training Loss:  tensor(0.0728, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "76  Training Loss:  tensor(0.0185, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "77  Training Loss:  tensor(0.2575, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "78  Training Loss:  tensor(0.0327, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "79  Training Loss:  tensor(0.0040, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "80  Training Loss:  tensor(0.1286, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "81  Training Loss:  tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "82  Training Loss:  tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "83  Training Loss:  tensor(0.0939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "84  Training Loss:  tensor(0.0179, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "85  Training Loss:  tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "86  Training Loss:  tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "87  Training Loss:  tensor(0.0033, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "88  Training Loss:  tensor(0.0898, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "89  Training Loss:  tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "90  Training Loss:  tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "91  Training Loss:  tensor(0.0313, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "92  Training Loss:  tensor(0.0137, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "93  Training Loss:  tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "94  Training Loss:  tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "95  Training Loss:  tensor(0.0120, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "96  Training Loss:  tensor(0.0169, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "97  Training Loss:  tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "98  Training Loss:  tensor(0.0190, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "99  Training Loss:  tensor(0.1384, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "100  Training Loss:  tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "101  Training Loss:  tensor(0.0082, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "102  Training Loss:  tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "103  Training Loss:  tensor(0.0919, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "104  Training Loss:  tensor(0.0038, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "105  Training Loss:  tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "106  Training Loss:  tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "107  Training Loss:  tensor(0.0839, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "108  Training Loss:  tensor(0.3336, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "109  Training Loss:  tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "110  Training Loss:  tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "111  Training Loss:  tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "112  Training Loss:  tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "113  Training Loss:  tensor(0.0278, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "114  Training Loss:  tensor(0.0062, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "115  Training Loss:  tensor(0.0126, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "116  Training Loss:  tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "117  Training Loss:  tensor(0.0057, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "118  Training Loss:  tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "119  Training Loss:  tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "120  Training Loss:  tensor(0.0138, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "121  Training Loss:  tensor(0.0127, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "122  Training Loss:  tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "123  Training Loss:  tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "124  Training Loss:  tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "125  Training Loss:  tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "126  Training Loss:  tensor(0.0862, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "127  Training Loss:  tensor(0.0253, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "128  Training Loss:  tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "129  Training Loss:  tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "130  Training Loss:  tensor(0.0516, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "131  Training Loss:  tensor(0.0075, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "132  Training Loss:  tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "133  Training Loss:  tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "134  Training Loss:  tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "135  Training Loss:  tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "136  Training Loss:  tensor(0.3548, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "137  Training Loss:  tensor(0.2507, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "138  Training Loss:  tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "139  Training Loss:  tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "140  Training Loss:  tensor(0.0626, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "141  Training Loss:  tensor(0.1259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "142  Training Loss:  tensor(0.0109, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "143  Training Loss:  tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "144  Training Loss:  tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "145  Training Loss:  tensor(0.0301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "146  Training Loss:  tensor(0.0369, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "147  Training Loss:  tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "148  Training Loss:  tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "149  Training Loss:  tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "150  Training Loss:  tensor(0.0221, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "151  Training Loss:  tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "152  Training Loss:  tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "153  Training Loss:  tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "154  Training Loss:  tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "155  Training Loss:  tensor(0.0200, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "156  Training Loss:  tensor(0.1204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "157  Training Loss:  tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "158  Training Loss:  tensor(0.1625, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "159  Training Loss:  tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "160  Training Loss:  tensor(0.0166, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "161  Training Loss:  tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "162  Training Loss:  tensor(0.0125, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "163  Training Loss:  tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "164  Training Loss:  tensor(0.0071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "165  Training Loss:  tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "166  Training Loss:  tensor(0.0216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "167  Training Loss:  tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "168  Training Loss:  tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "169  Training Loss:  tensor(0.0509, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "170  Training Loss:  tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "171  Training Loss:  tensor(0.1012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "172  Training Loss:  tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "173  Training Loss:  tensor(0.0228, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "174  Training Loss:  tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "175  Training Loss:  tensor(0.0268, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "176  Training Loss:  tensor(0.0280, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "177  Training Loss:  tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "178  Training Loss:  tensor(0.0186, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "179  Training Loss:  tensor(0.0096, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "180  Training Loss:  tensor(0.0134, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "181  Training Loss:  tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "182  Training Loss:  tensor(0.0074, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "183  Training Loss:  tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "184  Training Loss:  tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "185  Training Loss:  tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "186  Training Loss:  tensor(0.0054, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "187  Training Loss:  tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "188  Training Loss:  tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "189  Training Loss:  tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "190  Training Loss:  tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "191  Training Loss:  tensor(0.1150, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "192  Training Loss:  tensor(0.0319, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "193  Training Loss:  tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "194  Training Loss:  tensor(0.0058, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "195  Training Loss:  tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "196  Training Loss:  tensor(0.0451, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "197  Training Loss:  tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "198  Training Loss:  tensor(0.0064, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "199  Training Loss:  tensor(0.0046, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "200  Training Loss:  tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "201  Training Loss:  tensor(0.0063, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "202  Training Loss:  tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "203  Training Loss:  tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "204  Training Loss:  tensor(0.1309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "205  Training Loss:  tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "206  Training Loss:  tensor(0.0393, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "207  Training Loss:  tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "208  Training Loss:  tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "209  Training Loss:  tensor(0.0001, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "210  Training Loss:  tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "211  Training Loss:  tensor(0.0089, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "212  Training Loss:  tensor(0.1431, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "213  Training Loss:  tensor(0.0343, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "214  Training Loss:  tensor(0.5252, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "215  Training Loss:  tensor(0.0939, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "216  Training Loss:  tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "217  Training Loss:  tensor(0.0426, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "218  Training Loss:  tensor(0.1537, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "219  Training Loss:  tensor(0.0621, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "220  Training Loss:  tensor(0.0992, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "221  Training Loss:  tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "222  Training Loss:  tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "223  Training Loss:  tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "224  Training Loss:  tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "225  Training Loss:  tensor(0.3071, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "226  Training Loss:  tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "227  Training Loss:  tensor(0.0754, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "228  Training Loss:  tensor(0.0209, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "229  Training Loss:  tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "230  Training Loss:  tensor(0.0023, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "231  Training Loss:  tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "232  Training Loss:  tensor(0.0035, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "233  Training Loss:  tensor(0.0261, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "234  Training Loss:  tensor(0.0130, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "235  Training Loss:  tensor(0.0204, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "236  Training Loss:  tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "237  Training Loss:  tensor(0.0100, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "238  Training Loss:  tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "239  Training Loss:  tensor(0.0497, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "240  Training Loss:  tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "241  Training Loss:  tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "242  Training Loss:  tensor(0.7543, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "243  Training Loss:  tensor(0.0294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "244  Training Loss:  tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "245  Training Loss:  tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "246  Training Loss:  tensor(0.0210, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "247  Training Loss:  tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "248  Training Loss:  tensor(0.0031, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "249  Training Loss:  tensor(0.0321, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "250  Training Loss:  tensor(0.0022, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "251  Training Loss:  tensor(0.0257, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "252  Training Loss:  tensor(0.0697, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "253  Training Loss:  tensor(0.0199, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "254  Training Loss:  tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "255  Training Loss:  tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "256  Training Loss:  tensor(0.0301, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "257  Training Loss:  tensor(0.0092, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "258  Training Loss:  tensor(0.5935, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "259  Training Loss:  tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "260  Training Loss:  tensor(0.0564, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "261  Training Loss:  tensor(0.0894, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "262  Training Loss:  tensor(0.0087, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "263  Training Loss:  tensor(0.0069, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "264  Training Loss:  tensor(0.0086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "265  Training Loss:  tensor(0.0309, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "266  Training Loss:  tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "267  Training Loss:  tensor(0.0216, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "268  Training Loss:  tensor(0.0053, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "269  Training Loss:  tensor(0.0215, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "270  Training Loss:  tensor(0.0117, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "271  Training Loss:  tensor(0.0090, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "272  Training Loss:  tensor(0.0246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "273  Training Loss:  tensor(0.0381, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "274  Training Loss:  tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "275  Training Loss:  tensor(0.0287, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "276  Training Loss:  tensor(0.0072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "277  Training Loss:  tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "278  Training Loss:  tensor(0.0073, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "279  Training Loss:  tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "280  Training Loss:  tensor(0.0097, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "281  Training Loss:  tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "282  Training Loss:  tensor(0.0365, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "283  Training Loss:  tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "284  Training Loss:  tensor(0.0787, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "285  Training Loss:  tensor(0.0098, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "286  Training Loss:  tensor(0.0056, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "287  Training Loss:  tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "288  Training Loss:  tensor(0.0039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "289  Training Loss:  tensor(0.0401, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "290  Training Loss:  tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "291  Training Loss:  tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "292  Training Loss:  tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "293  Training Loss:  tensor(0.0282, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "294  Training Loss:  tensor(0.0030, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "295  Training Loss:  tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "296  Training Loss:  tensor(0.1415, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "297  Training Loss:  tensor(0.0104, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "298  Training Loss:  tensor(0.0804, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "299  Training Loss:  tensor(0.0107, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "300  Training Loss:  tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "301  Training Loss:  tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "302  Training Loss:  tensor(0.0511, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "303  Training Loss:  tensor(0.0192, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "304  Training Loss:  tensor(0.0085, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "305  Training Loss:  tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "306  Training Loss:  tensor(0.0132, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "307  Training Loss:  tensor(0.0139, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "308  Training Loss:  tensor(0.0246, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "309  Training Loss:  tensor(0.0364, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "310  Training Loss:  tensor(0.1019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "311  Training Loss:  tensor(0.0032, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "312  Training Loss:  tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "313  Training Loss:  tensor(0.8573, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "314  Training Loss:  tensor(0.0034, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "315  Training Loss:  tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "316  Training Loss:  tensor(0.0014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "317  Training Loss:  tensor(0.0006, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "318  Training Loss:  tensor(0.0027, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "319  Training Loss:  tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "320  Training Loss:  tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "321  Training Loss:  tensor(0.0020, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "322  Training Loss:  tensor(0.0041, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "323  Training Loss:  tensor(0.0443, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "324  Training Loss:  tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "325  Training Loss:  tensor(0.6039, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "326  Training Loss:  tensor(0.0042, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "327  Training Loss:  tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "328  Training Loss:  tensor(0.0595, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "329  Training Loss:  tensor(0.0019, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "330  Training Loss:  tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "331  Training Loss:  tensor(0.0007, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "332  Training Loss:  tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "333  Training Loss:  tensor(0.0324, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "334  Training Loss:  tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "335  Training Loss:  tensor(0.0158, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "336  Training Loss:  tensor(0.0065, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "337  Training Loss:  tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "338  Training Loss:  tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "339  Training Loss:  tensor(0.0740, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "340  Training Loss:  tensor(0.0003, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "341  Training Loss:  tensor(0.0408, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "342  Training Loss:  tensor(0.0045, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "343  Training Loss:  tensor(0.0025, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "344  Training Loss:  tensor(0.0037, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "345  Training Loss:  tensor(0.0048, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "346  Training Loss:  tensor(0.0113, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "347  Training Loss:  tensor(0.0047, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "348  Training Loss:  tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "349  Training Loss:  tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "350  Training Loss:  tensor(0.0358, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "351  Training Loss:  tensor(0.3776, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "352  Training Loss:  tensor(0.0964, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "353  Training Loss:  tensor(0.2483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "354  Training Loss:  tensor(0.0066, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "355  Training Loss:  tensor(0.0353, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "356  Training Loss:  tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "357  Training Loss:  tensor(0.1306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "358  Training Loss:  tensor(0.0012, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "359  Training Loss:  tensor(0.5570, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "360  Training Loss:  tensor(0.0374, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "361  Training Loss:  tensor(0.0254, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "362  Training Loss:  tensor(0.0143, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "363  Training Loss:  tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "364  Training Loss:  tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "365  Training Loss:  tensor(0.0070, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "366  Training Loss:  tensor(0.0111, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "367  Training Loss:  tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "368  Training Loss:  tensor(0.0196, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "369  Training Loss:  tensor(0.0727, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "370  Training Loss:  tensor(0.0337, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "371  Training Loss:  tensor(0.0483, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "372  Training Loss:  tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "373  Training Loss:  tensor(0.0202, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "374  Training Loss:  tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "375  Training Loss:  tensor(0.0009, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "376  Training Loss:  tensor(0.0226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "377  Training Loss:  tensor(0.3014, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "378  Training Loss:  tensor(0.0036, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "379  Training Loss:  tensor(0.0015, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "380  Training Loss:  tensor(0.1248, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "381  Training Loss:  tensor(0.0294, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "382  Training Loss:  tensor(0.0226, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "383  Training Loss:  tensor(0.3072, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "384  Training Loss:  tensor(0.0958, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "385  Training Loss:  tensor(0.0055, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "386  Training Loss:  tensor(0.0068, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "387  Training Loss:  tensor(0.1167, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "388  Training Loss:  tensor(0.0533, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "389  Training Loss:  tensor(0.3149, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "390  Training Loss:  tensor(0.0043, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "391  Training Loss:  tensor(0.2576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "392  Training Loss:  tensor(0.0306, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "393  Training Loss:  tensor(0.1086, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "394  Training Loss:  tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "395  Training Loss:  tensor(0.0164, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "396  Training Loss:  tensor(0.0049, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "397  Training Loss:  tensor(0.0195, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "398  Training Loss:  tensor(0.0604, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "399  Training Loss:  tensor(0.0743, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "400  Training Loss:  tensor(0.0050, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "401  Training Loss:  tensor(0.0251, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "402  Training Loss:  tensor(0.0576, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "403  Training Loss:  tensor(0.0197, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "404  Training Loss:  tensor(0.0277, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "405  Training Loss:  tensor(0.0021, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "406  Training Loss:  tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "407  Training Loss:  tensor(0.0067, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "408  Training Loss:  tensor(0.0024, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "409  Training Loss:  tensor(0.0629, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "410  Training Loss:  tensor(0.0060, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "411  Training Loss:  tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "412  Training Loss:  tensor(0.0915, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "413  Training Loss:  tensor(0.0235, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "414  Training Loss:  tensor(0.0011, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "415  Training Loss:  tensor(0.0010, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "416  Training Loss:  tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "417  Training Loss:  tensor(0.0170, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "418  Training Loss:  tensor(0.0259, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "419  Training Loss:  tensor(0.0029, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "420  Training Loss:  tensor(0.3281, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "421  Training Loss:  tensor(0.0013, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "422  Training Loss:  tensor(0.0016, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "423  Training Loss:  tensor(0.0017, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "424  Training Loss:  tensor(0.1211, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "425  Training Loss:  tensor(0.1749, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "426  Training Loss:  tensor(0.0723, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "427  Training Loss:  tensor(0.0005, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "428  Training Loss:  tensor(0.0501, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "429  Training Loss:  tensor(0.0394, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "430  Training Loss:  tensor(0.0493, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "431  Training Loss:  tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "432  Training Loss:  tensor(0.0316, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "433  Training Loss:  tensor(0.0004, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "434  Training Loss:  tensor(0.0008, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "435  Training Loss:  tensor(0.0932, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "436  Training Loss:  tensor(0.0028, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "437  Training Loss:  tensor(0.0052, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.33      0.38        27\n",
            "           1       0.94      0.94      0.94       381\n",
            "           2       0.87      0.91      0.89        92\n",
            "\n",
            "    accuracy                           0.90       500\n",
            "   macro avg       0.74      0.73      0.73       500\n",
            "weighted avg       0.90      0.90      0.90       500\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_preds, total_labels = [], []\n",
        "for batch in test_dataloader:\n",
        "    input_ids = batch[0].to(device)\n",
        "    attention_mask = batch[1].to(device)\n",
        "    labels = batch[2].to(device)\n",
        "    total_labels.append(labels.cpu().numpy())\n",
        "\n",
        "    output = model(input_ids, attention_mask)\n",
        "    loss = loss_fn(output, labels)\n",
        "    # print(\"Validation Loss: \", loss)\n",
        "\n",
        "    preds = torch.argmax(output, dim=1)\n",
        "    total_preds.append(preds.cpu().numpy())\n",
        "\n",
        "total_labels, total_preds = np.concatenate(total_labels), np.concatenate(total_preds)\n",
        "print(classification_report(total_labels, total_preds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBAoq7y0yC4h",
        "outputId": "890dc9a7-f3d6-4519-ea70-d39b4fa0a7c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.46      0.34      0.39        53\n",
            "           1       0.94      0.95      0.94       778\n",
            "           2       0.85      0.88      0.86       169\n",
            "\n",
            "    accuracy                           0.90      1000\n",
            "   macro avg       0.75      0.72      0.73      1000\n",
            "weighted avg       0.90      0.90      0.90      1000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "accuracy_score(total_labels, total_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBTH0WcQ2sK6",
        "outputId": "8bb1f123-85b3-42fc-b8dc-f705f3a30bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.902"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zer, one, two = 0, 0, 0\n",
        "for i in total_labels:\n",
        "    if i == 0:\n",
        "        zer+=1\n",
        "    elif i == 1:\n",
        "        one+=1\n",
        "    else:\n",
        "        two+=1\n",
        "print(zer, one, two)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OetKvbzX29oX",
        "outputId": "45436b7c-eb40-4449-c898-2b43b5d6179b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "53 778 169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zer, one, two = 0, 0, 0\n",
        "for i in total_preds:\n",
        "    if i == 0:\n",
        "        zer+=1\n",
        "    elif i == 1:\n",
        "        one+=1\n",
        "    else:\n",
        "        two+=1\n",
        "print(zer, one, two)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zLzniT_55eq",
        "outputId": "13b95882-093f-488e-ed7c-adc899c717ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39 787 174\n"
          ]
        }
      ]
    }
  ]
}