{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3G0WZkDfuzt",
        "outputId": "cf73cfba-9f25-48e5-a2bb-3ab77dded4d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       class                                    processed_tweet\n",
            "18831      1  rt dakwhi kaewhy270 peopl forget logic behind ...\n",
            "1132       1  8220beardedgemini 8220ginasanabria hoe yah nig...\n",
            "14616      1  rt causewereguy your littl bitch httptco92flic...\n",
            "848        2  mt commiss gouach tiki wahin monkey tube surf ...\n",
            "11497      1  ever saw kendal jone person id kill sight hate...\n",
            "...      ...                                                ...\n",
            "6957       1  salome110thebe1 what good bitch ass nigga catc...\n",
            "19067      2  rt grind2tim dont think even real relationship...\n",
            "9948       1                     how bitch wear high heal right\n",
            "2558       1          barbod6fcb u lame bitch get fuck gay shit\n",
            "5216       2                            yellabeautykc home coon\n",
            "\n",
            "[1600 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# Assuming your DataFrame is named df\n",
        "# ...\n",
        "df1 = pd.read_csv(\"/content/hate_speech_dataset.csv\")\n",
        "df = df1.sample(n=2000, random_state=40)\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Function for text cleaning and preprocessing\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "\n",
        "    # Remove special characters, links, etc.\n",
        "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Lowercasing\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply the preprocessing function to the entire 'tweet' column\n",
        "train_df['processed_tweet'] = train_df['tweet'].apply(preprocess_text)\n",
        "\n",
        "# Display the preprocessed DataFrame\n",
        "print(train_df[['class', 'processed_tweet']])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT embeddings"
      ],
      "metadata": {
        "id": "NTu_CVZptunn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, TFBertModel\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize and get BERT embeddings\n",
        "def get_bert_embeddings(text):\n",
        "    # Tokenize text\n",
        "    tokens = tokenizer.encode(text, max_length=128, truncation=True, padding='max_length', return_tensors='tf')\n",
        "\n",
        "    # Get BERT embeddings\n",
        "    embeddings = bert_model(tokens)['last_hidden_state']\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "# Apply the function to the entire 'processed_tweet' column\n",
        "train_df['bert_embeddings'] = train_df['processed_tweet'].apply(get_bert_embeddings)\n",
        "\n",
        "# Display the DataFrame with 'class', 'processed_tweet', and 'bert_embeddings' columns\n",
        "print(train_df[['class', 'processed_tweet', 'bert_embeddings']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cO-Uf1Wrz4u",
        "outputId": "2c17c363-8e7a-48c7-b28d-89915746a11c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       class                                    processed_tweet  \\\n",
            "18831      1  rt dakwhi kaewhy270 peopl forget logic behind ...   \n",
            "1132       1  8220beardedgemini 8220ginasanabria hoe yah nig...   \n",
            "14616      1  rt causewereguy your littl bitch httptco92flic...   \n",
            "848        2  mt commiss gouach tiki wahin monkey tube surf ...   \n",
            "11497      1  ever saw kendal jone person id kill sight hate...   \n",
            "...      ...                                                ...   \n",
            "6957       1  salome110thebe1 what good bitch ass nigga catc...   \n",
            "19067      2  rt grind2tim dont think even real relationship...   \n",
            "9948       1                     how bitch wear high heal right   \n",
            "2558       1          barbod6fcb u lame bitch get fuck gay shit   \n",
            "5216       2                            yellabeautykc home coon   \n",
            "\n",
            "                                         bert_embeddings  \n",
            "18831  (((tf.Tensor(-0.34693128, shape=(), dtype=floa...  \n",
            "1132   (((tf.Tensor(-0.37257406, shape=(), dtype=floa...  \n",
            "14616  (((tf.Tensor(-0.379819, shape=(), dtype=float3...  \n",
            "848    (((tf.Tensor(-0.4548126, shape=(), dtype=float...  \n",
            "11497  (((tf.Tensor(-0.44532642, shape=(), dtype=floa...  \n",
            "...                                                  ...  \n",
            "6957   (((tf.Tensor(-0.4511808, shape=(), dtype=float...  \n",
            "19067  (((tf.Tensor(-0.40760237, shape=(), dtype=floa...  \n",
            "9948   (((tf.Tensor(-0.34454656, shape=(), dtype=floa...  \n",
            "2558   (((tf.Tensor(-0.4521768, shape=(), dtype=float...  \n",
            "5216   (((tf.Tensor(-0.44493917, shape=(), dtype=floa...  \n",
            "\n",
            "[1600 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passing through channels"
      ],
      "metadata": {
        "id": "Xm2-Pezt1ER3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Bidirectional, GRU, Concatenate, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Assuming 'bert_embeddings' contains the BERT embeddings in train_df\n",
        "bert_embeddings_shape = train_df['bert_embeddings'].iloc[0].shape\n",
        "\n",
        "# Create Input layer for BERT embeddings\n",
        "bert_input = Input(shape=bert_embeddings_shape[1:], name=\"bert_input\")\n",
        "\n",
        "# BERT+CNN\n",
        "conv_output = Conv1D(filters=64, kernel_size=3, activation='relu')(bert_input)\n",
        "cnn_output = GlobalMaxPooling1D()(conv_output)\n",
        "\n",
        "# BERT+biGRU\n",
        "bi_gru_output = Bidirectional(GRU(32, return_sequences=True))(bert_input)\n",
        "gru_output = GlobalMaxPooling1D()(bi_gru_output)\n",
        "\n",
        "# Concatenate outputs\n",
        "concatenated_features = Concatenate()([cnn_output, gru_output])\n",
        "\n",
        "# Fully Connected Layer and Softmax\n",
        "fc_layer = Dense(units=128, activation='relu')(concatenated_features)\n",
        "output_layer = Dense(units=3, activation='softmax')(fc_layer)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=bert_input, outputs=output_layer)\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Assuming 'bert_embeddings' is a numpy array containing the BERT embeddings\n",
        "bert_embeddings_array = np.stack(train_df['bert_embeddings'].values)[:, 0, :, :]\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    x=bert_embeddings_array,\n",
        "    y=train_df['class'],\n",
        "    epochs=5,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQg9rCDU1Gg7",
        "outputId": "003066cc-a335-4027-c9a5-0a83dc931374"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " bert_input (InputLayer)     [(None, 128, 768)]           0         []                            \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)           (None, 126, 64)              147520    ['bert_input[0][0]']          \n",
            "                                                                                                  \n",
            " bidirectional_4 (Bidirecti  (None, 128, 64)              153984    ['bert_input[0][0]']          \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " global_max_pooling1d_8 (Gl  (None, 64)                   0         ['conv1d_4[0][0]']            \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " global_max_pooling1d_9 (Gl  (None, 64)                   0         ['bidirectional_4[0][0]']     \n",
            " obalMaxPooling1D)                                                                                \n",
            "                                                                                                  \n",
            " concatenate_4 (Concatenate  (None, 128)                  0         ['global_max_pooling1d_8[0][0]\n",
            " )                                                                  ',                            \n",
            "                                                                     'global_max_pooling1d_9[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " dense_7 (Dense)             (None, 128)                  16512     ['concatenate_4[0][0]']       \n",
            "                                                                                                  \n",
            " dense_8 (Dense)             (None, 3)                    387       ['dense_7[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 318403 (1.21 MB)\n",
            "Trainable params: 318403 (1.21 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/5\n",
            "40/40 [==============================] - 6s 44ms/step - loss: 0.6262 - accuracy: 0.7688 - val_loss: 0.5704 - val_accuracy: 0.8031\n",
            "Epoch 2/5\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.4081 - accuracy: 0.8492 - val_loss: 0.6383 - val_accuracy: 0.7844\n",
            "Epoch 3/5\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.2442 - accuracy: 0.9180 - val_loss: 0.5042 - val_accuracy: 0.8375\n",
            "Epoch 4/5\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.1428 - accuracy: 0.9633 - val_loss: 0.6096 - val_accuracy: 0.8125\n",
            "Epoch 5/5\n",
            "40/40 [==============================] - 1s 28ms/step - loss: 0.0574 - accuracy: 0.9883 - val_loss: 0.5367 - val_accuracy: 0.8156\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79778ff09540>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test preprocess"
      ],
      "metadata": {
        "id": "mkNLecVX32IA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "# Assuming your DataFrame is named df\n",
        "# ...\n",
        "df1 = pd.read_csv(\"/content/hate_speech_dataset.csv\")\n",
        "df = df1.sample(n=2000, random_state=40)\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Function for text cleaning and preprocessing\n",
        "def preprocess_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return ''\n",
        "\n",
        "    # Remove special characters, links, etc.\n",
        "    text = re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Lowercasing\n",
        "    tokens = [word.lower() for word in tokens]\n",
        "\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "\n",
        "    # Stemming\n",
        "    stemmer = PorterStemmer()\n",
        "    tokens = [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "# Apply the preprocessing function to the entire 'tweet' column\n",
        "test_df['processed_tweet'] = test_df['tweet'].apply(preprocess_text)\n",
        "\n",
        "# Display the preprocessed DataFrame\n",
        "print(test_df[['class', 'processed_tweet']])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Yf2CHro330X",
        "outputId": "d04414d7-2cae-4369-aca9-a12f6579e55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       class                                    processed_tweet\n",
            "24708      1                                   u sell dat pussi\n",
            "9191       1                                 free hoe 1x 128520\n",
            "5841       1                 denythepropheci that dragon retard\n",
            "1532       1  8220stevestfl relationship end life stop whini...\n",
            "22468      1  walk parti playin nelli air forc one walk outt...\n",
            "...      ...                                                ...\n",
            "20479      1                               readi bounc di bitch\n",
            "12666      1       lo bitch told name start could fucka b c got\n",
            "1202       1  8220condeezy3 gamehom alon noth dosomeon come ...\n",
            "21126      1                   spell name right bitch well talk\n",
            "13208      1            naw bitch goin monster lol lyric maniac\n",
            "\n",
            "[400 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test embedding"
      ],
      "metadata": {
        "id": "aH1qJY0h3jwD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, TFBertModel\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize and get BERT embeddings\n",
        "def get_bert_embeddings(text):\n",
        "    # Tokenize text\n",
        "    tokens = tokenizer.encode(text, max_length=128, truncation=True, padding='max_length', return_tensors='tf')\n",
        "\n",
        "    # Get BERT embeddings\n",
        "    embeddings = bert_model(tokens)['last_hidden_state']\n",
        "\n",
        "    return embeddings\n",
        "\n",
        "# Apply the function to the entire 'processed_tweet' column\n",
        "test_df['bert_embeddings'] = test_df['processed_tweet'].apply(get_bert_embeddings)\n",
        "\n",
        "# Display the DataFrame with 'class', 'processed_tweet', and 'bert_embeddings' columns\n",
        "print(test_df[['class', 'processed_tweet', 'bert_embeddings']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MYlrXGw3lFn",
        "outputId": "8cc92781-aba8-42ec-a153-658461ce665c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Assuming 'bert_embeddings_test' is a numpy array containing the BERT embeddings for test_df\n",
        "bert_embeddings_array_test = np.stack(test_df['bert_embeddings'].values)[:, 0, :, :]\n",
        "\n",
        "# Predict class probabilities for each sample\n",
        "predictions = model.predict(bert_embeddings_array_test)\n",
        "\n",
        "# Get the predicted class for each sample\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Calculate precision, recall, and f1 score for each class\n",
        "precision_scores = precision_score(test_df['class'], predicted_classes, average=None)\n",
        "recall_scores = recall_score(test_df['class'], predicted_classes, average=None)\n",
        "f1_scores = f1_score(test_df['class'], predicted_classes, average=None)\n",
        "\n",
        "# Display precision, recall, and f1 score for each class\n",
        "for class_label, precision, recall, f1 in zip(range(3), precision_scores, recall_scores, f1_scores):\n",
        "    print(f\"Class {class_label}: Precision = {precision:.4f}, Recall = {recall:.4f}, F1 Score = {f1:.4f}\")\n",
        "\n",
        "# Alternatively, you can use classification_report for a comprehensive report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(test_df['class'], predicted_classes))\n"
      ],
      "metadata": {
        "id": "4ofI6pPF1bjb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}